{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "# gensim\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "\n",
    "# sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# logging for gensim (set to INFO)\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "from textblob import TextBlob, Word\n",
    "\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edited version of AOC to make it more organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 400)  # or 199"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, preprocessing (using same code as for kickstarter as baseline, come back here to tweak later)\n",
    "\n",
    "Look into https://pypi.org/project/tweet-preprocessor/ for tweet processing later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "# nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "\n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    #lemmatize with Spacy\n",
    "    doc = nlp(text)\n",
    "    text = \" \".join([token.lemma_ for token in doc])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_stopwords = stopwords.words('english') + \\\n",
    "    ['rt', 'https', 'http', 'amp', 'via', 'one', 'around', 'would', 'let', 'could', 'going', 'like', \n",
    "     'get', 'may', 'says', 'say', 'make', 'based', 'even', 'another', 'completely', 'thanks', 'way', \n",
    "     'find', 'used', 'thing', '2019', 'see', 'need', 'know', 'knows', 'think', 'thinks', 'take', 'new', \n",
    "     'day', 'days', 'captain', 'marvel', 'mcu', 'captainmarvel', 'pron']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/df_0.pickle', 'rb') as f:\n",
    "    df_0 = pickle.load(f)\n",
    "\n",
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/df_1.pickle', 'rb') as f:\n",
    "    df_1 = pickle.load(f)\n",
    "    \n",
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/df_2.pickle', 'rb') as f:\n",
    "    df_2 = pickle.load(f)\n",
    "    \n",
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/df_3.pickle', 'rb') as f:\n",
    "    df_3 = pickle.load(f)\n",
    "    \n",
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/df_4.pickle', 'rb') as f:\n",
    "    df_4 = pickle.load(f)\n",
    "    \n",
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/df_5.pickle', 'rb') as f:\n",
    "    df_5 = pickle.load(f)\n",
    "    \n",
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/df_6.pickle', 'rb') as f:\n",
    "    df_6 = pickle.load(f)\n",
    "    \n",
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/df_7.pickle', 'rb') as f:\n",
    "    df_7 = pickle.load(f)\n",
    "    \n",
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/df_11.pickle', 'rb') as f:\n",
    "    df_11 = pickle.load(f)\n",
    "    \n",
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/df_15.pickle', 'rb') as f:\n",
    "    df_15 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0['final_text'] = np.where((df_0['retweet_text'].isnull() == False), df_0['retweet_text'], df_0['main_text'])\n",
    "df_1['final_text'] = np.where((df_1['retweet_text'].isnull() == False), df_1['retweet_text'], df_1['main_text'])\n",
    "df_2['final_text'] = np.where((df_2['retweet_text'].isnull() == False), df_2['retweet_text'], df_2['main_text'])\n",
    "df_3['final_text'] = np.where((df_3['retweet_text'].isnull() == False), df_3['retweet_text'], df_3['main_text'])\n",
    "df_4['final_text'] = np.where((df_4['retweet_text'].isnull() == False), df_4['retweet_text'], df_4['main_text'])\n",
    "df_5['final_text'] = np.where((df_5['retweet_text'].isnull() == False), df_5['retweet_text'], df_5['main_text'])\n",
    "df_6['final_text'] = np.where((df_6['retweet_text'].isnull() == False), df_6['retweet_text'], df_6['main_text'])\n",
    "df_7['final_text'] = np.where((df_7['retweet_text'].isnull() == False), df_7['retweet_text'], df_7['main_text'])\n",
    "df_11['final_text'] = np.where((df_11['retweet_text'].isnull() == False), df_11['retweet_text'], df_11['main_text'])\n",
    "df_15['final_text'] = np.where((df_15['retweet_text'].isnull() == False), df_15['retweet_text'], df_15['main_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN ALL BELOW ONCE PREV IS FINISHED!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0['tweet_processed'] = df_0['final_text'].apply(lambda x:pre_process(x))\n",
    "df_1['tweet_processed'] = df_1['final_text'].apply(lambda x:pre_process(x))\n",
    "df_2['tweet_processed'] = df_2['final_text'].apply(lambda x:pre_process(x))\n",
    "df_3['tweet_processed'] = df_3['final_text'].apply(lambda x:pre_process(x))\n",
    "df_4['tweet_processed'] = df_4['final_text'].apply(lambda x:pre_process(x))\n",
    "df_5['tweet_processed'] = df_5['final_text'].apply(lambda x:pre_process(x))\n",
    "df_6['tweet_processed'] = df_6['final_text'].apply(lambda x:pre_process(x))\n",
    "df_7['tweet_processed'] = df_7['final_text'].apply(lambda x:pre_process(x))\n",
    "df_11['tweet_processed'] = df_11['final_text'].apply(lambda x:pre_process(x))\n",
    "df_15['tweet_processed'] = df_15['final_text'].apply(lambda x:pre_process(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/preproccessed_text/df_0_preprocess.pickle', 'wb') as to_write:\n",
    "    pickle.dump(df_0, to_write)\n",
    "\n",
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/preproccessed_text/df_1_preprocess.pickle', 'wb') as to_write:\n",
    "    pickle.dump(df_1, to_write)\n",
    "\n",
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/preproccessed_text/df_2_preprocess.pickle', 'wb') as to_write:\n",
    "    pickle.dump(df_2, to_write)\n",
    "\n",
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/preproccessed_text/df_3_preprocess.pickle', 'wb') as to_write:\n",
    "    pickle.dump(df_3, to_write)\n",
    "\n",
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/preproccessed_text/df_4_preprocess.pickle', 'wb') as to_write:\n",
    "    pickle.dump(df_4, to_write)\n",
    "\n",
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/preproccessed_text/df_5_preprocess.pickle', 'wb') as to_write:\n",
    "    pickle.dump(df_5, to_write)\n",
    "\n",
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/preproccessed_text/df_6_preprocess.pickle', 'wb') as to_write:\n",
    "    pickle.dump(df_6, to_write)\n",
    "\n",
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/preproccessed_text/df_7_preprocess.pickle', 'wb') as to_write:\n",
    "    pickle.dump(df_7, to_write)\n",
    "\n",
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/preproccessed_text/df_11_preprocess.pickle', 'wb') as to_write:\n",
    "    pickle.dump(df_11, to_write)\n",
    "\n",
    "with open('/Users/robertpagano/src/metis_project_kojak/network_files/marvel/community_pickles_pre_nlp/preproccessed_text/df_15_preprocess.pickle', 'wb') as to_write:\n",
    "    pickle.dump(df_15, to_write)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = df_1['tweet_processed']\n",
    "X_1 = df_1['tweet_processed']\n",
    "X_2 = df_2['tweet_processed']\n",
    "X_3 = df_3['tweet_processed']\n",
    "X_4 = df_4['tweet_processed']\n",
    "X_5 = df_5['tweet_processed']\n",
    "X_6 = df_6['tweet_processed']\n",
    "X_7 = df_7['tweet_processed']\n",
    "X_11 = df_11['tweet_processed']\n",
    "X_15 = df_15['tweet_processed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_0 = TfidfVectorizer(stop_words=tweet_stopwords, token_pattern=\"\\\\b[a-z][a-z]+\\\\b\", ngram_range=(1,2))\n",
    "tfidf_1 = TfidfVectorizer(stop_words=tweet_stopwords, token_pattern=\"\\\\b[a-z][a-z]+\\\\b\", ngram_range=(1,2))\n",
    "tfidf_2 = TfidfVectorizer(stop_words=tweet_stopwords, token_pattern=\"\\\\b[a-z][a-z]+\\\\b\", ngram_range=(1,2))\n",
    "tfidf_3 = TfidfVectorizer(stop_words=tweet_stopwords, token_pattern=\"\\\\b[a-z][a-z]+\\\\b\", ngram_range=(1,2))\n",
    "tfidf_4 = TfidfVectorizer(stop_words=tweet_stopwords, token_pattern=\"\\\\b[a-z][a-z]+\\\\b\", ngram_range=(1,2))\n",
    "tfidf_5 = TfidfVectorizer(stop_words=tweet_stopwords, token_pattern=\"\\\\b[a-z][a-z]+\\\\b\", ngram_range=(1,2))\n",
    "tfidf_6 = TfidfVectorizer(stop_words=tweet_stopwords, token_pattern=\"\\\\b[a-z][a-z]+\\\\b\", ngram_range=(1,2))\n",
    "tfidf_7 = TfidfVectorizer(stop_words=tweet_stopwords, token_pattern=\"\\\\b[a-z][a-z]+\\\\b\", ngram_range=(1,2))\n",
    "tfidf_11 = TfidfVectorizer(stop_words=tweet_stopwords, token_pattern=\"\\\\b[a-z][a-z]+\\\\b\", ngram_range=(1,2))\n",
    "tfidf_15 = TfidfVectorizer(stop_words=tweet_stopwords, token_pattern=\"\\\\b[a-z][a-z]+\\\\b\", ngram_range=(1,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Community_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28967975, 0.06303829, 0.07126341, 0.06829032, 0.04576414,\n",
       "       0.03643453, 0.01060932, 0.00745032, 0.0059875 , 0.00447338,\n",
       "       0.00461396, 0.00426893, 0.00413396, 0.00368238, 0.00301009,\n",
       "       0.00298623, 0.00297964, 0.00271909, 0.00250638, 0.00252132])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_0 = tfidf_0.fit_transform(X_0)\n",
    "lsa_0 = TruncatedSVD(20)\n",
    "doc_topic_0 = lsa_0.fit_transform(bag_of_words_0)\n",
    "lsa_0.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "co fvumqtm, fvumqtm, fvumqtm hj, hj, without context, without, context co, context, co, thor\n",
      "\n",
      "Topic  1\n",
      "widow, black widow, black, thor, widow train, thor watch, co ydfekkjae, train pistol, ydfekkjae, pistol co\n",
      "\n",
      "Topic  2\n",
      "want, want home, bitch niggas, want war, utcom, niggas want, home want, ftbp, co ftbp, ftbp utcom\n",
      "\n",
      "Topic  3\n",
      "facility endgame, co lczkximxrh, lczkximxrh, show avenger, endgame co, show, endgame, avenger facility, facility, avenger\n",
      "\n",
      "Topic  4\n",
      "co ovkuamt, ovkuamt xk, ovkuamt, thor battlefield, xk, battlefield co, battlefield, thor, co, thor co\n",
      "\n",
      "Topic  5\n",
      "fire, fire gun, widow fire, co vrq, facility thor, gun avenger, vrq, gun, thor co, black widow\n",
      "\n",
      "Topic  6\n",
      "business co, co jvb, avenger distract, distract thanos, tw, jvb, jvb tw, handle business, thor handle, thanos wait\n",
      "\n",
      "Topic  7\n",
      "mf bitch, mf, bitch, bad bitch, bad, really bitch, damn actually, drop international, actually drop, mf flex\n",
      "\n",
      "Topic  8\n",
      "worth, worth watch, worth good, watch, worth hype, go, good, worth avenger, jbendana give, give worth\n",
      "\n",
      "Topic  9\n",
      "larson, brie larson, brie, go, samuel jackson, samuel, jackson, larson samuel, ring, yu\n",
      "\n",
      "Topic  10\n",
      "go, vs thanos, imax worthy, worthy fight, go imax, fight ready, worthy, thanos go, imax, ready\n",
      "\n",
      "Topic  11\n",
      "brielarson, adidashoop brielarson, xvz, co xvz, xvz lrglzw, okayyy, lrglzw, okayyy adidashoop, brielarson co, adidashoop\n",
      "\n",
      "Topic  12\n",
      "avenger endgame, endgame trailer, gunn, trailer, trailer drop, heart jam, toomuuch, toomuuch co, guardian toomuuch, co cp\n",
      "\n",
      "Topic  13\n",
      "open weekend, weekend higherfurtherfaster, higherfurtherfaster co, higherfurtherfaster, fan, open, weekend, pop, saturday, pop theater\n",
      "\n",
      "Topic  14\n",
      "go, look brie, larson understand, family look, forget dead, dead family, thor forget, dead, family, forget\n",
      "\n",
      "Topic  15\n",
      "go, slap, definitely go, slap skin, right else, skin right, go slap, skin, thor definitely, definitely\n",
      "\n",
      "Topic  16\n",
      "stan, lee, stan lee, intro, lee co, change, ok, intro image, image stan, change intro\n",
      "\n",
      "Topic  17\n",
      "spoiler, spoiler without, wlzwectivx, co wlzwectivx, spoiler context, context, context co, without, without context, co\n",
      "\n",
      "Topic  18\n",
      "love, good, carol, chance win, originalfunko, originalfunko chance, follow originalfunko, follow, win, chance\n",
      "\n",
      "Topic  19\n",
      "love, congrat brielarson, wpy, wpy sveuvf, brielarson well, co wpy, deserve co, boom congrat, well deserve, sveuvf\n"
     ]
    }
   ],
   "source": [
    "display_topics(lsa_0, tfidf_0.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Community_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28967975, 0.06303829, 0.07126341, 0.06829032, 0.04576414,\n",
       "       0.03643453, 0.01060932, 0.00745032, 0.00598745, 0.00447332,\n",
       "       0.00461379, 0.00426922, 0.00413456, 0.00368372, 0.00302664,\n",
       "       0.00299894, 0.00297355, 0.00267876, 0.0025251 , 0.00254885])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_1 = tfidf_1.fit_transform(X_1)\n",
    "lsa_1 = TruncatedSVD(20)\n",
    "doc_topic_1 = lsa_1.fit_transform(bag_of_words_1)\n",
    "lsa_1.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "co fvumqtm, fvumqtm, fvumqtm hj, hj, without context, without, context co, context, co, thor\n",
      "\n",
      "Topic  1\n",
      "widow, black widow, black, thor, widow train, thor watch, co ydfekkjae, train pistol, ydfekkjae, pistol co\n",
      "\n",
      "Topic  2\n",
      "want, want home, bitch niggas, want war, utcom, niggas want, home want, ftbp, co ftbp, ftbp utcom\n",
      "\n",
      "Topic  3\n",
      "facility endgame, co lczkximxrh, lczkximxrh, show avenger, endgame co, show, endgame, avenger facility, facility, avenger\n",
      "\n",
      "Topic  4\n",
      "co ovkuamt, ovkuamt xk, ovkuamt, thor battlefield, xk, battlefield co, battlefield, thor, co, thor co\n",
      "\n",
      "Topic  5\n",
      "fire, fire gun, widow fire, co vrq, facility thor, gun avenger, vrq, gun, thor co, black widow\n",
      "\n",
      "Topic  6\n",
      "jvb tw, avenger distract, distract thanos, tw, thor handle, jvb, co jvb, business co, handle business, thanos wait\n",
      "\n",
      "Topic  7\n",
      "mf bitch, mf, bitch, bad bitch, bad, really bitch, drop international, damn actually, mf flex, actually drop\n",
      "\n",
      "Topic  8\n",
      "worth, worth watch, worth good, watch, worth hype, go, jbendana give, give worth, worth avenger, jbendana\n",
      "\n",
      "Topic  9\n",
      "larson, brie larson, brie, go, samuel jackson, samuel, jackson, larson samuel, ring, co lczhmmq\n",
      "\n",
      "Topic  10\n",
      "go, vs thanos, worthy fight, go imax, fight ready, imax worthy, worthy, thanos go, imax, ready\n",
      "\n",
      "Topic  11\n",
      "brielarson, adidashoop brielarson, co xvz, okayyy, okayyy adidashoop, xvz lrglzw, xvz, lrglzw, brielarson co, adidashoop\n",
      "\n",
      "Topic  12\n",
      "avenger endgame, endgame trailer, gunn, trailer, trailer drop, lawdt, officially close, guardian toomuuch, disney fox, toomuuch co\n",
      "\n",
      "Topic  13\n",
      "open weekend, weekend higherfurtherfaster, higherfurtherfaster co, higherfurtherfaster, fan, open, weekend, pop, saturday, fan open\n",
      "\n",
      "Topic  14\n",
      "go, slap, look brie, larson understand, thor forget, dead family, forget dead, family look, dead, family\n",
      "\n",
      "Topic  15\n",
      "look brie, thor forget, dead family, forget dead, larson understand, family look, family, dead, understand, forget\n",
      "\n",
      "Topic  16\n",
      "lee, stan lee, stan, intro, lee co, change, ok, ivh, co ivh, ivh ok\n",
      "\n",
      "Topic  17\n",
      "spoiler, spoiler without, co wlzwectivx, wlzwectivx, spoiler context, good, context, context co, co, love\n",
      "\n",
      "Topic  18\n",
      "love, good, congrat brielarson, deserve co, wpy sveuvf, brielarson well, wpy, sveuvf, co wpy, well deserve\n",
      "\n",
      "Topic  19\n",
      "congrat brielarson, boom congrat, sveuvf, deserve co, brielarson well, well deserve, wpy sveuvf, wpy, co wpy, boom\n"
     ]
    }
   ],
   "source": [
    "display_topics(lsa_1, tfidf_1.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Community_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04040905, 0.0221644 , 0.01081053, 0.01120958, 0.00828544,\n",
       "       0.00769537, 0.00721827, 0.00574295, 0.00620663, 0.00578497,\n",
       "       0.00592726, 0.00588957, 0.00564478, 0.00555213, 0.00538718,\n",
       "       0.00532296, 0.00503983, 0.00489027, 0.00436428, 0.00413235])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_2 = tfidf_2.fit_transform(X_2)\n",
    "lsa_2 = TruncatedSVD(20)\n",
    "doc_topic_2 = lsa_2.fit_transform(bag_of_words_2)\n",
    "lsa_2.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "weekend higherfurtherfaster, open weekend, higherfurtherfaster co, higherfurtherfaster, fan, open, weekend, brielarson pop, night surprise, theater saturday\n",
      "\n",
      "Topic  1\n",
      "ultimate experience, popcorn soda, soda, help fan, fan popcorn, ultimate, popcorn, help, experience, experience brielarson\n",
      "\n",
      "Topic  2\n",
      "studio, co, ticket, ticket co, ulr, co ulr, theater ticket, theater, ulr lzx, lzx co\n",
      "\n",
      "Topic  3\n",
      "lee co, stan lee, lee, stan, change, intro, image stan, intro image, ivh, co ivh\n",
      "\n",
      "Topic  4\n",
      "sveuvf, wpy sveuvf, boom congrat, co wpy, well deserve, wpy, brielarson well, boom, deserve co, congrat brielarson\n",
      "\n",
      "Topic  5\n",
      "uylpevb, co uylpevb, intro roll, roll co, roll, intro, co, avengersendgame, intro co, avengersendgame theater\n",
      "\n",
      "Topic  6\n",
      "avengersendgame, avengersendgame theater, studio avengersendgame, theater april, april co, april, whatev watch, trailer studio, brand trailer, watch brand\n",
      "\n",
      "Topic  7\n",
      "co uugwmtwqt, uugwmtwqt, proud co, proud, co, context, context co, avengersendgame co, thor, thanos thor\n",
      "\n",
      "Topic  8\n",
      "avengersendgame co, farm avengersendgame, thanos thor, farm, thor run, run farm, oog, ypcyc, co oog, oog ypcyc\n",
      "\n",
      "Topic  9\n",
      "happy, choose, woman, context, context co, internationalwomensday, happy internationalwomensday, internationalwomensday cast, cast, without context\n",
      "\n",
      "Topic  10\n",
      "cq ug, ug pivn, pivn, logo change, co cq, change stan, cq, ug, logo, co uylpevb\n",
      "\n",
      "Topic  11\n",
      "context co, context, without context, without, spoiler, co fvumqtm, fvumqtm, fvumqtm hj, hj, spoiler without\n",
      "\n",
      "Topic  12\n",
      "cat, history miss, call cool, cool cat, cat critic, critic call, cat movie, movie history, critic, cool\n",
      "\n",
      "Topic  13\n",
      "htohktois, co htohktois, weekend co, wakanda across, cheer wakanda, fhpwndnvyx, co fhpwndnvyx, across universe, universe brielarson, wakanda\n",
      "\n",
      "Topic  14\n",
      "weekend co, wakanda across, cheer wakanda, fhpwndnvyx, co fhpwndnvyx, across universe, universe brielarson, wakanda, brielarson weekend, cheer\n",
      "\n",
      "Topic  15\n",
      "internationalwomensday, originalfunko chance, follow originalfunko, originalfunko, chance win, chance, follow, win, internationalwomensday cast, happy internationalwomensday\n",
      "\n",
      "Topic  16\n",
      "internationalwomensday cast, happy internationalwomensday, cast, internationalwomensday, happy, co qz, qz, cast co, cast studio, studio co\n",
      "\n",
      "Topic  17\n",
      "brielarson samuelljackson, samuelljackson, test, app co, watch free, carpoolkaraoke, arianagrande, appletv app, free appletv, appletv\n",
      "\n",
      "Topic  18\n",
      "world, movie world, studio movie, movie, box, box office, office, world theater, high, go\n",
      "\n",
      "Topic  19\n",
      "studio movie, movie world, world, world theater, cllxd, co cllxd, world ticket, ticket, movie, cheer wakanda\n"
     ]
    }
   ],
   "source": [
    "display_topics(lsa_2, tfidf_2.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Community_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12655283, 0.09293576, 0.09037782, 0.08112643, 0.07417496,\n",
       "       0.06547991, 0.04233742, 0.03303307, 0.02231412, 0.0148271 ,\n",
       "       0.01324264, 0.01187566, 0.01167761, 0.01036296, 0.00945058,\n",
       "       0.00795511, 0.00739407, 0.00586535, 0.00546535, 0.00538644])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_3 = tfidf_3.fit_transform(X_3)\n",
    "lsa_3 = TruncatedSVD(20)\n",
    "doc_topic_3 = lsa_3.fit_transform(bag_of_words_3)\n",
    "lsa_3.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "co wjebx, yxxpsg co, co yxxpsg, wjebx, wjebx qp, yxxpsg, qp, captainmarvelxboxsweepstake nopurchnec, xbox captainmarvelxboxsweepstake, march rule\n",
      "\n",
      "Topic  1\n",
      "pop, follow originalfunko, originalfunko chance, originalfunko, chance win, win, follow, funkowomenofpower, chance, funkowomenofpower internationalwomensday\n",
      "\n",
      "Topic  2\n",
      "box, box close, order mcc, mcc box, mcc, box order, win collector, close march, corp box, collector corp\n",
      "\n",
      "Topic  3\n",
      "lwzcakbfsy, co lwzcakbfsy, win walmart, walmart exclusive, walmart, exclusive pop, pop co, exclusive, wtrgxd, co kne\n",
      "\n",
      "Topic  4\n",
      "co kne, wtrgxd, kne wtrgxd, kne, pop goosethecat, cat pop, win goose, goosethecat co, goosethecat, goose cat\n",
      "\n",
      "Topic  5\n",
      "uxvbxgpunv, co uxvbxgpunv, win chase, pop funkowomenofpower, chase pop, chase, funkowomenofpower internationalwomensday, internationalwomensday co, internationalwomensday, funkowomenofpower\n",
      "\n",
      "Topic  6\n",
      "nkyuxukvwf, co nkyuxukvwf, exclusive korath, korath pop, pop funkoeccc, win eccc, funkoeccc co, eccc exclusive, funkoeccc, korath\n",
      "\n",
      "Topic  7\n",
      "exclusive pack, dorbz bundle, pack dorbz, bundle funkowomenofpower, funko shop, shop exclusive, jgehy, co csl, csl jgehy, csl\n",
      "\n",
      "Topic  8\n",
      "sbsa, sbsa jm, iv sbsa, ok gm, jm co, co iv, iv, co ok, gm, jm\n",
      "\n",
      "Topic  9\n",
      "cs co, th cs, cs, answer chance, marveluk winner, correct answer, reply correct, captainmarvelxboxsweepstak marveluk, follow reply, xbox captainmarvelxboxsweepstak\n",
      "\n",
      "Topic  10\n",
      "iszekchfk, co iszekchfk, funkowomenofpower internationalwomensday, internationalwomensday co, internationalwomensday, exclusive, csl, jgehy, csl jgehy, co csl\n",
      "\n",
      "Topic  11\n",
      "follow retweet, win co, retweet marvelousprizegiveaway, klyqcd jnd, ci utlz, qyfcmliltm, utlz, utlz rule, sg ci, klyqcd\n",
      "\n",
      "Topic  12\n",
      "yl id, ccokpkxvcs, ccokpkxvcs co, co ccokpkxvcs, id qw, id, xbox captainmarvelxboxcont, captainmarvelxboxcont nopurchnec, qw, co yl\n",
      "\n",
      "Topic  13\n",
      "follow chance, originalfunko prize, win originalfunko, talos goose, ver talos, pack ver, mystery character, cat mystery, saxlbpz co, saxlbpz\n",
      "\n",
      "Topic  14\n",
      "away set, figure follow, marvellegend figure, set marvellegend, dm co, win country, winner dm, country welcome, welcome winner, marvellegend\n",
      "\n",
      "Topic  15\n",
      "fyjv qx, ipdn, ipdn gi, co ipdn, gi co, co fyjv, fyjv, gi, qx, cs co\n",
      "\n",
      "Topic  16\n",
      "co fqujk, win gitd, fqujk zc, fqujk, gitd walmart, gitd, zc, follow chance, pop co, walmart exclusive\n",
      "\n",
      "Topic  17\n",
      "tygvbtxmh, wuiojhc co, wuiojhc, captainmarvelimaxprizegiveaway chance, co tygvbtxmh, khkdfoazso rule, khkdfoazso, co khkdfoazso, qv wuiojhc, retweet captainmarvelimaxprizegiveaway\n",
      "\n",
      "Topic  18\n",
      "competition, enter, weekend, uk, funko pop, open, bag, bundle, open weekend, win bundle\n",
      "\n",
      "Topic  19\n",
      "kitty, icymi kitty, goose humanizing, kitty kitty, superhero pet, humanizing, humanizing appeal, pet goosethecat, appeal superhero, kitty goose\n"
     ]
    }
   ],
   "source": [
    "display_topics(lsa_3, tfidf_3.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Community_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04360452, 0.04029493, 0.02579917, 0.01700832, 0.01770867,\n",
       "       0.01649673, 0.01333475, 0.01209863, 0.01132071, 0.00974927,\n",
       "       0.00907375, 0.00920448, 0.00729515, 0.00730978, 0.00709057,\n",
       "       0.00603571, 0.00564932, 0.00547563, 0.00539442, 0.00541835])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_4 = tfidf_4.fit_transform(X_4)\n",
    "lsa_4 = TruncatedSVD(20)\n",
    "doc_topic_4 = lsa_4.fit_transform(bag_of_words_4)\n",
    "lsa_4.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "brielarson, model draw, xd enjoy, draw xd, since star, credit sailor, moon role, ohfhak, co ohfhak, brielarson credit\n",
      "\n",
      "Topic  1\n",
      "ykreclow, co ykreclow, brielarson president, president co, president, brielarson, co, hvuzhv co, hvuzhv, motherfuck love\n",
      "\n",
      "Topic  2\n",
      "war, ragnarok historical, operation homecoming, war overpopulation, terrorism ragnarok, military operation, historical revisionism, homecoming unemployment, man sponsor, scarce resource\n",
      "\n",
      "Topic  3\n",
      "hvuzhv, xwhbaqfvw, co xwhbaqfvw, co hvuzhv, motherfuck love, hvuzhv co, motherfuck, love samuel, jackson co, samuel jackson\n",
      "\n",
      "Topic  4\n",
      "hijab marvelstudios, co xdlktuc, marvelstudios badass, decide design, xdlktuc, design hijab, hero high, badass hero, hijab, faster co\n",
      "\n",
      "Topic  5\n",
      "reference, movie, spend reference, therealstanlee shout, friend therealstanlee, universe survive, shout part, lifetime spend, mess lifetime, marvelstudio friend\n",
      "\n",
      "Topic  6\n",
      "hashtag, click hashtag, cat background, trend hashtag, hashtag welcome, um korea, background click, korea trend, hashtag goose, goose people\n",
      "\n",
      "Topic  7\n",
      "movie juicy, htnzqx nvc, htnzqx, co htnzqx, jumpsuit fucking, nvc, fucking power, power move, juicy jumpsuit, jumpsuit\n",
      "\n",
      "Topic  8\n",
      "dg fdo, fan kid, fdo, time comic, co dg, amazing time, kid co, dg, comic fan, fan\n",
      "\n",
      "Topic  9\n",
      "go flop, half billi, co lhhrs, lhhrs bud, lhhrs, flop half, billi less, billi, people film, feel people\n",
      "\n",
      "Topic  10\n",
      "movie, lead, female lead, lead superhero, female, superhero movie, first, superhero, man, weekend higherfurtherfaster\n",
      "\n",
      "Topic  11\n",
      "weekend higherfurtherfaster, open weekend, higherfurtherfaster co, higherfurtherfaster, open, weekend, pop theater, theater saturday, night surprise, brielarson pop\n",
      "\n",
      "Topic  12\n",
      "bez, co bez, jqox, world fragile, bez jqox, grateful introduce, introduce world, fragile male, male movie, movie review\n",
      "\n",
      "Topic  13\n",
      "yes, yes amazing, obsession cat, amazing obsession, co vuzexoyxs, vuzexoyxs, obsession, cat goose, goose co, goose\n",
      "\n",
      "Topic  14\n",
      "first, man, opening top, movi first, top first, movie pander, movie spider, pander sjws, first iron, man movi\n",
      "\n",
      "Topic  15\n",
      "sveuvf, boom congrat, wpy sveuvf, wpy, co wpy, well deserve, brielarson well, deserve co, boom, congrat brielarson\n",
      "\n",
      "Topic  16\n",
      "woman, every, perfect girl, write never, trade write, consumer prove, trip consumer, well trade, bridesmaid pitch, stop wonder\n",
      "\n",
      "Topic  17\n",
      "ww, samoanjyandall co, yuxwhhlz, love gorgeous, wish great, gorgeous piece, crew wish, ww crew, congratulation team, whole ww\n",
      "\n",
      "Topic  18\n",
      "dir, fleck co, boden ryan, dir anna, ryan fleck, fleck, ryan, anna boden, co cxoqhhdmfv, cxoqhhdmfv\n",
      "\n",
      "Topic  19\n",
      "co jrnhi, owu, jrnhi owu, jrnhi, yes go, go brielarson, butt co, kick butt, butt, brielarson kick\n"
     ]
    }
   ],
   "source": [
    "display_topics(lsa_4, tfidf_4.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Community_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05224814, 0.06405837, 0.05646166, 0.04148708, 0.04522894,\n",
       "       0.03533295, 0.02914876, 0.03245864, 0.03206032, 0.0315328 ,\n",
       "       0.03169025, 0.02287117, 0.02199024, 0.01752033, 0.01726561,\n",
       "       0.01293848, 0.00937351, 0.00947109, 0.00927093, 0.00842558])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_5 = tfidf_5.fit_transform(X_5)\n",
    "lsa_5 = TruncatedSVD(20)\n",
    "doc_topic_5 = lsa_5.fit_transform(bag_of_words_5)\n",
    "lsa_5.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "thor, thor never, never aim, rws, aim, aim head, head avengersendgame, flinch thor, co rws, flinch\n",
      "\n",
      "Topic  1\n",
      "co ybavku, ybavku, scar co, scar, co, logo co, inspire logo, co rnuixscvsh, rnuixscvsh, mavel inspire\n",
      "\n",
      "Topic  2\n",
      "iron man, iron, man, avenger iron, avenger, man incredible, incredible hulk, hulk, incredible, america first\n",
      "\n",
      "Topic  3\n",
      "rnuixscvsh, mavel, mavel inspire, inspire logo, co rnuixscvsh, logo co, inspire, logo, summarize, py eh\n",
      "\n",
      "Topic  4\n",
      "summarize, summarize video, py eh, co py, eh yk, py, eh, yk, video co, video\n",
      "\n",
      "Topic  5\n",
      "jb, paradigm, hall movie, gsc paradigm, gsc, hall, seat, paradigm mall, time seat, place gsc\n",
      "\n",
      "Topic  6\n",
      "loyal, loyal bestie, co xrlaxmo, xrlaxmo, bestie co, bestie, co, leave credit, still people, co pyqrf\n",
      "\n",
      "Topic  7\n",
      "leave credit, pyqrf rvkp, co pyqrf, rvkp, still people, already st, pyqrf, movie yet, yet still, people leave\n",
      "\n",
      "Topic  8\n",
      "never nick, bct, fury singing, mmmi, mmmi bct, co mmmi, ring co, singing ring, singing, nick fury\n",
      "\n",
      "Topic  9\n",
      "kiky, co jxn, jxn eu, kiky cat, jxn, cat flerken, eu, flerken co, flerken, cat\n",
      "\n",
      "Topic  10\n",
      "co gjps, studio retweet, gjps likz, gjps, likz, fast secure, tweet captainmarvelmy, retweet tweet, secure ticket, captainmarvelmy co\n",
      "\n",
      "Topic  11\n",
      "tribute co, kind spoiler, qmfuyee, co qmfuyee, spoiler stan, lee tribute, kind, tribute, spoiler, lee\n",
      "\n",
      "Topic  12\n",
      "gentleman thanos, shake co, thanos shake, tp rx, lady gentleman, gentleman, rx, shake, lady, co tp\n",
      "\n",
      "Topic  13\n",
      "without context, context, context co, without, co fvumqtm, fvumqtm hj, hj, fvumqtm, spoiler without, co fzesbwid\n",
      "\n",
      "Topic  14\n",
      "oleh, senarai, mengikut kronologi, mengikut, senarai movie, kronologi oleh, oleh kevin, kronologi, movie mengikut, president studio\n",
      "\n",
      "Topic  15\n",
      "watch, road become, become watch, brielarson sky, sky studio, many feat, feat road, road, sky, feat\n",
      "\n",
      "Topic  16\n",
      "co crcalrzofi, crcalrzofi, spoiler co, watch co, spoiler, thanos watch, co kerqvlz, ry, kerqvlz ry, kerqvlz\n",
      "\n",
      "Topic  17\n",
      "co crcalrzofi, crcalrzofi, spoiler co, spoiler, become, spoiler without, fzesbwid, co fzesbwid, congrat, drawing congrat\n",
      "\n",
      "Topic  18\n",
      "drawing congrat, widow gamora, gagfunoff week, timelapse drawing, gagfunoff, week winner, co bsdoh, tylorhepner, bsdoh iuio, tylorhepner ig\n",
      "\n",
      "Topic  19\n",
      "end, end game, game, woi, tak, avenger end, end credit, pun tak, trailer end, lak\n"
     ]
    }
   ],
   "source": [
    "display_topics(lsa_5, tfidf_5.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Community_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03100691, 0.01792091, 0.01688233, 0.01516062, 0.01164227,\n",
       "       0.01140538, 0.0110262 , 0.01123518, 0.00997816, 0.00919846,\n",
       "       0.00808808, 0.00724714, 0.00679672, 0.0059257 , 0.00535652,\n",
       "       0.00504265, 0.00457967, 0.00460596, 0.00432974, 0.00417823])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_6 = tfidf_6.fit_transform(X_6)\n",
    "lsa_6 = TruncatedSVD(20)\n",
    "doc_topic_6 = lsa_6.fit_transform(bag_of_words_6)\n",
    "lsa_6.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "woman immediately, son come, room seem, kind bigotry, police win, celebrate utterly, win tolerate, patronizing counterproductive, counterproductive celebrate, tolerate kind\n",
      "\n",
      "Topic  1\n",
      "df ivjzzu, opening monologue, review perfection, ivjzzu, monologue rlm, monologue, rlm review, perfection co, co df, rlm\n",
      "\n",
      "Topic  2\n",
      "troop, thank, name thank, troop real, superhero troop, midnight tonight, back join, add name, hi samuel, live american\n",
      "\n",
      "Topic  3\n",
      "critic, movie, co pzyk, opinion fit, pzyk, pzyk uwcws, afraid hate, lie happy, life critic, internationalwomensday female\n",
      "\n",
      "Topic  4\n",
      "nuke, pic, audience, review, pic left, pic right, rat order, rating pic, right minute, rottentomatoe mass\n",
      "\n",
      "Topic  5\n",
      "woman co, base real, exploit supreme, life exploit, supreme leader, jong un, leader kim, popular western, kim jong, un thinly\n",
      "\n",
      "Topic  6\n",
      "plot, hole many, give poorly, plot plot, write jumpy, go regret, contrivance, plot contrivance, regret movie, many plot\n",
      "\n",
      "Topic  7\n",
      "trump, planet, supporter complicit, complicit, trump supporter, supporter, unemployment number, number boom, complicit ruin, ha gz\n",
      "\n",
      "Topic  8\n",
      "murder, parent, tell baseball, baseball little, destroy last, superman entire, planet destroy, batman parent, baseball, uncle\n",
      "\n",
      "Topic  9\n",
      "wonderwoman co, wonderwoman, hpdxnbrqjg, co hpdxnbrqjg, good wonderwoman, good, co, co bnmjkhcbzb, bnmjkhcbzb, strong wonderwoman\n",
      "\n",
      "Topic  10\n",
      "dwvkimsqxh, co dwvkimsqxh, wonder woman, wonder, woman co, woman, co, lead, important, female lead\n",
      "\n",
      "Topic  11\n",
      "brie larson, larson, brie, drink terrible, delivery absolutely, pig narrative, save popcorn, role line, awful cast, also push\n",
      "\n",
      "Topic  12\n",
      "result, search, worthy search, search term, boost top, channel artificially, co upqmnxbo, top search, source mainstream, medium channel\n",
      "\n",
      "Topic  13\n",
      "important, lead, super important, overlook billion, movie overlook, evil franchise, lead milla, film resident, jovovich important, franchise lead\n",
      "\n",
      "Topic  14\n",
      "gt, complete confidence, gt close, course shazam, confidence opinion, opinion course, shazam gt, film complete, confidence, complete\n",
      "\n",
      "Topic  15\n",
      "boycott, alitachallenge, launch, jack posobiec, posobiec, jack, battle angel, angel, alita battle, alita\n",
      "\n",
      "Topic  16\n",
      "call, feminist, people, brainwash sell, attack liberal, entertain guy, people progressive, feminist brainwash, liberal show, sell pretty\n",
      "\n",
      "Topic  17\n",
      "fighter pilot, fighter, pilot, female, female fighter, jeannie leavitt, jeannie, leavitt, usairforce first, usairforce\n",
      "\n",
      "Topic  18\n",
      "fighter pilot, fighter, pilot, female, female fighter, jeannie, jeannie leavitt, leavitt, usairforce first, gen jeannie\n",
      "\n",
      "Topic  19\n",
      "woman corny, corny ass, realize open, open international, ass shit, corny, international woman, international, realize, ass\n"
     ]
    }
   ],
   "source": [
    "display_topics(lsa_6, tfidf_6.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Community_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15482183, 0.05758228, 0.04712704, 0.03127667, 0.03007945,\n",
       "       0.03032132, 0.02429275, 0.02356071, 0.02161187, 0.01809549,\n",
       "       0.01654174, 0.0148685 , 0.01147911, 0.01005909, 0.00853592,\n",
       "       0.00805964, 0.00781883, 0.00722712, 0.00695422, 0.00671655])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_7 = tfidf_7.fit_transform(X_7)\n",
    "lsa_7 = TruncatedSVD(20)\n",
    "doc_topic_7 = lsa_7.fit_transform(bag_of_words_7)\n",
    "lsa_7.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "really, want boring, boring bland, cat really, bland sam, jackson cat, really want, sam jackson, sam, boring\n",
      "\n",
      "Topic  1\n",
      "go avenger, theater ashamed, endgame time, total badass, love total, damn excited, badass post, dawg op, excited go, op love\n",
      "\n",
      "Topic  2\n",
      "good, woman good, unpopular opinion, unpopular, opinion wonder, wonder woman, wonder, opinion, woman, popular\n",
      "\n",
      "Topic  3\n",
      "movie, tl dr, tl, magic, landmark magic, also sjw, leftish, decent shrug, female action, anything also\n",
      "\n",
      "Topic  4\n",
      "kceihtpkop, sneezing co, co kceihtpkop, sneezing, co, bar, fury, awesome, bar bud, fury converse\n",
      "\n",
      "Topic  5\n",
      "awesome, fantastic, eat healthy, home cook, meal absolutely, love awesome, session fun, good vibe, fun stream, cook meal\n",
      "\n",
      "Topic  6\n",
      "trailer time, time hour, ultimate duo, thor ultimate, duo watch, dawg thor, watch trailer, duo, hour, ultimate\n",
      "\n",
      "Topic  7\n",
      "bar, fury, hawkeye recreate, co fqgd, actual bar, yes actual, bar nick, bar bud, obviously co, fqgd sl\n",
      "\n",
      "Topic  8\n",
      "fantastic, good, meal, stream, night pal, awesome night, fantastic great, today fantastic, meal absolutely, healthy home\n",
      "\n",
      "Topic  9\n",
      "guy, honest assume, assume guy, sexist male, guy lmao, lmao sexist, male pig, assume, pig, lmao\n",
      "\n",
      "Topic  10\n",
      "good, feel, random, fun, movie, really good, bad, good fun, go smash, leave cinema\n",
      "\n",
      "Topic  11\n",
      "time two, two daughter, thanos trouble, twice weekend, daughter thanos, trouble, second time, weekend second, twice, daughter\n",
      "\n",
      "Topic  12\n",
      "imagine leave, credit movie, cinema credit, though really, smash avenger, story go, real though, leave cinema, come sooner, go smash\n",
      "\n",
      "Topic  13\n",
      "random, feel, night, bad, neck stiff, headache neck, go ago, bad headache, night bad, ago since\n",
      "\n",
      "Topic  14\n",
      "co, brielarson, open weekend, weekend higherfurtherfaster, higherfurtherfaster co, higherfurtherfaster, open, fan, pop, fan open\n",
      "\n",
      "Topic  15\n",
      "co fdnmqeiiy, fdnmqeiiy, popular fact, fact wonder, good co, popular, fact, co, co kf, rp\n",
      "\n",
      "Topic  16\n",
      "entire goonsquad, goonsquad co, rp, kf ehlo, ehlo rp, kf, ehlo, co kf, goonsquad, entire\n",
      "\n",
      "Topic  17\n",
      "feel, bad start, really first, start feel, familiar, feel familiar, familiar cool, first feel, cool good, good job\n",
      "\n",
      "Topic  18\n",
      "fun stream, fantastic great, good vibe, cook meal, cook, meal absolutely, gym, gym session, night pal, stream good\n",
      "\n",
      "Topic  19\n",
      "deserve co, co wpy, well deserve, boom congrat, boom, wpy, congrat brielarson, sveuvf, wpy sveuvf, brielarson well\n"
     ]
    }
   ],
   "source": [
    "display_topics(lsa_7, tfidf_7.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Community_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12003292, 0.11778732, 0.09167505, 0.04478375, 0.02790912,\n",
       "       0.02099542, 0.0185694 , 0.01806148, 0.01352641, 0.01236449,\n",
       "       0.01105531, 0.01105033, 0.01030782, 0.00991043, 0.00930064,\n",
       "       0.00778772, 0.00748445, 0.00621288, 0.00607933, 0.00589165])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_11 = tfidf_11.fit_transform(X_11)\n",
    "lsa_11 = TruncatedSVD(20)\n",
    "doc_topic_11 = lsa_11.fit_transform(bag_of_words_11)\n",
    "lsa_11.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "parent, move parent, basement, female next, next move, parent basement, next, move, female, movie\n",
      "\n",
      "Topic  1\n",
      "sweat, favorite part, uhhh marveling, uhhh, sweat uhhh, love favorite, date love, part sweat, marveling, favorite\n",
      "\n",
      "Topic  2\n",
      "bad idk, whether go, neckbeard bad, pound, go review, pound dude, good hand, bunch pound, dude neckbeard, hand bunch\n",
      "\n",
      "Topic  3\n",
      "movie without, watch superhero, neckbeard boycott, dust burp, boycott nice, without cheeto, actually glad, burp, nice watch, glad neckbeard\n",
      "\n",
      "Topic  4\n",
      "whip wildly, head whip, wildly lady, whip, fun head, lady hear, wildly, head, hear, lady\n",
      "\n",
      "Topic  5\n",
      "weirdo thank, multi billion, weirdo, world embarrassing, medium review, slop, slop pretend, letter medium, corporate slop, corporate\n",
      "\n",
      "Topic  6\n",
      "aadmi, umbrella academy, everyday matlab, everyday, chupi, chupi badla, drop show, date everyday, open netflix, doll\n",
      "\n",
      "Topic  7\n",
      "ask, bohemian rhapsody, headphone, bohemian, rhapsody, ask bohemian, international, woman, international woman, headphone wait\n",
      "\n",
      "Topic  8\n",
      "layer today, shin celebration, sneaker, shin, sneaker sun, celebration, today sneaker, layer, celebration good, sun shin\n",
      "\n",
      "Topic  9\n",
      "never, movie, brie larson, larson, brie, really, movie dd, dd star, handsome, power brie\n",
      "\n",
      "Topic  10\n",
      "watch, watch watch, watch part, hour loop, trooper, trooper hour, scene starship, starship trooper, starship, part scene\n",
      "\n",
      "Topic  11\n",
      "kick ass, kick, ass, prefer, space movie, sing planet, rock band, band aerosmith, agent fury, agent\n",
      "\n",
      "Topic  12\n",
      "co, ad, publication, yous, thank yous, recruitment tool, god mkhut, military publication, great recruitment, write great\n",
      "\n",
      "Topic  13\n",
      "co, xwhbaqfvw, co hvuzhv, jackson co, love samuel, hvuzhv co, hvuzhv, motherfuck, motherfuck love, co xwhbaqfvw\n",
      "\n",
      "Topic  14\n",
      "activism bux, happy brie, million political, bux weekend, bux, larson million, political activism, million, activism, political\n",
      "\n",
      "Topic  15\n",
      "murca, look, caaahh, ihhh caaahh, merr, ahhh, ahhh merr, ihhh, merr ihhh, america\n",
      "\n",
      "Topic  16\n",
      "white woman, finally, woman, woman look, finally talk, look finally, manager, talk manager, white, talk\n",
      "\n",
      "Topic  17\n",
      "cat, interrogate, interrogate cat, naturally, naturally interrogate, nice cat, nice, go cat, many, go\n",
      "\n",
      "Topic  18\n",
      "book, comic book, comic, promote, fucking good, base, fucking, book movie, promotion, promotion comic\n",
      "\n",
      "Topic  19\n",
      "fucking good, fucking, good, many, co, brielarson, interrogate cat, interrogate, naturally, naturally interrogate\n"
     ]
    }
   ],
   "source": [
    "display_topics(lsa_11, tfidf_11.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Community_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44614817, 0.01694105, 0.01099905, 0.0109376 , 0.00900884,\n",
       "       0.00605395, 0.00552942, 0.00491899, 0.0044471 , 0.00441569,\n",
       "       0.00399101, 0.00372945, 0.00337048, 0.00308458, 0.00290979,\n",
       "       0.00276216, 0.0027453 , 0.00256277, 0.00252182, 0.00235015])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_15 = tfidf_15.fit_transform(X_15)\n",
    "lsa_15 = TruncatedSVD(20)\n",
    "doc_topic_15 = lsa_15.fit_transform(bag_of_words_15)\n",
    "lsa_15.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "lczhmmq, lczhmmq yu, yu, duetting, duetting ring, ring something, jackson duetting, something co, co lczhmmq, larson samuel\n",
      "\n",
      "Topic  1\n",
      "context co, context, without context, without, co fvumqtm, fvumqtm hj, fvumqtm, hj, co, spoiler\n",
      "\n",
      "Topic  2\n",
      "higherfurtherfaster co, weekend higherfurtherfaster, open weekend, higherfurtherfaster, open, fan, weekend, brielarson, theater, surprise fan\n",
      "\n",
      "Topic  3\n",
      "nine inch, nail, inch, nail shirt, inch nail, nine, shirt leather, motorcycle wear, pandering interest, pandering\n",
      "\n",
      "Topic  4\n",
      "larson slander, co otrizk, absolutely brie, timeline co, otrizk asd, slander timeline, asd, otrizk, slander, timeline\n",
      "\n",
      "Topic  5\n",
      "originalfunko, follow originalfunko, originalfunko chance, chance win, chance, follow, win, pop, funkowomenofpower, funkowomenofpower internationalwomensday\n",
      "\n",
      "Topic  6\n",
      "cool, really, time, go, watch, buy, help, really show, date th, hey boyfriend\n",
      "\n",
      "Topic  7\n",
      "go, watch, good, go watch, want, want go, wanna, feel, cinema, still\n",
      "\n",
      "Topic  8\n",
      "box, box office, office, lashanalynch co, lashanalynch, check interview, check, wonderful lashanalynch, exf co, exf\n",
      "\n",
      "Topic  9\n",
      "help fan, popcorn soda, soda, fan popcorn, ultimate experience, popcorn, ultimate, experience, brielarson help, experience brielarson\n",
      "\n",
      "Topic  10\n",
      "stan, stan lee, lee, last, lee cameo, cameo, cameo co, co hg, hg, feel watch\n",
      "\n",
      "Topic  11\n",
      "good, really, really good, movie, love, bitch, last, stan, good movie, stan lee\n",
      "\n",
      "Topic  12\n",
      "xh cm, xh, co shuh, shuh xh, shuh, cm, review co, review, finally, finally review\n",
      "\n",
      "Topic  13\n",
      "scene co, scene, co viyvsvg, viyvsvg, far favorite, night far, last night, favorite scene, far, favorite\n",
      "\n",
      "Topic  14\n",
      "watch, really, bitch, really bitch, cinema, amazing, still, love, endgame, avenger\n",
      "\n",
      "Topic  15\n",
      "amazing, love, movie, brielarson, time, love brielarson, watch, love brie, woman, ticket\n",
      "\n",
      "Topic  16\n",
      "bitch, really, amazing, go, really bitch, love, wanna, brielarson, stan, wanna go\n",
      "\n",
      "Topic  17\n",
      "ticket, someone, pls, buy ticket, someone buy, ticket pls, love, buy, studio, movie\n",
      "\n",
      "Topic  18\n",
      "love, brielarson, love brie, love brielarson, woman, brielarson love, still, international woman, international, carol\n",
      "\n",
      "Topic  19\n",
      "endgame, avenger, avenger endgame, cinema, please avenger, late please, rubbish, nigerian cinema, nigerian, cinema week\n"
     ]
    }
   ],
   "source": [
    "display_topics(lsa_15, tfidf_15.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have my top words in each LSA object w/ 20 topics each. I'm going to pickle each model and then use a new file to:\n",
    " - Find which tweets score the highest in each topic to get examples\n",
    " - Name communities\n",
    " - Sentiment analysis (maybe weekend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/lsa_marvel/lsa_0.pickle', 'wb') as to_write:\n",
    "    pickle.dump(lsa_0, to_write)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/lsa_marvel/lsa_1.pickle', 'wb') as to_write:\n",
    "    pickle.dump(lsa_1, to_write)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/lsa_marvel/lsa_2.pickle', 'wb') as to_write:\n",
    "    pickle.dump(lsa_2, to_write)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/lsa_marvel/lsa_3.pickle', 'wb') as to_write:\n",
    "    pickle.dump(lsa_3, to_write)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/lsa_marvel/lsa_4.pickle', 'wb') as to_write:\n",
    "    pickle.dump(lsa_4, to_write)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/lsa_marvel/lsa_5.pickle', 'wb') as to_write:\n",
    "    pickle.dump(lsa_5, to_write)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/lsa_marvel/lsa_6.pickle', 'wb') as to_write:\n",
    "    pickle.dump(lsa_6, to_write)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/lsa_marvel/lsa_7.pickle', 'wb') as to_write:\n",
    "    pickle.dump(lsa_7, to_write)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/lsa_marvel/lsa_11.pickle', 'wb') as to_write:\n",
    "    pickle.dump(lsa_11, to_write)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/lsa_marvel/lsa_15.pickle', 'wb') as to_write:\n",
    "    pickle.dump(lsa_15, to_write)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF Models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106.26531036149292\n",
      "\n",
      "Topic  0\n",
      "co fvumqtm, fvumqtm, fvumqtm hj, hj, without context, without, context co, context, co, context pt\n",
      "\n",
      "Topic  1\n",
      "ydfekkjae, co ydfekkjae, thor watch, train pistol, widow train, pistol co, watch black, pistol, train, watch\n",
      "\n",
      "Topic  2\n",
      "want, want home, ftbp utcom, utcom, want war, co ftbp, home want, ftbp, niggas want, bitch niggas\n",
      "\n",
      "Topic  3\n",
      "lczkximxrh, co lczkximxrh, facility endgame, show avenger, endgame co, show, endgame, avenger facility, facility, avenger\n",
      "\n",
      "Topic  4\n",
      "thor battlefield, co ovkuamt, ovkuamt xk, ovkuamt, xk, battlefield co, battlefield, thor, co, thanos thor\n",
      "\n",
      "Topic  5\n",
      "gun avenger, fire gun, facility thor, widow fire, vrq, co vrq, gun, fire, thor co, avenger facility\n",
      "\n",
      "Topic  6\n",
      "business co, tw, thor handle, avenger distract, jvb tw, distract thanos, handle business, jvb, co jvb, wait thor\n",
      "\n",
      "Topic  7\n",
      "mf bitch, mf, bitch, bad bitch, bad, really bitch, actually drop, drop international, woman mf, damn actually\n",
      "\n",
      "Topic  8\n",
      "worth, worth watch, worth good, worth hype, watch, worth avenger, give worth, jbendana give, jbendana, hype\n",
      "\n",
      "Topic  9\n",
      "samuel jackson, samuel, jackson, larson samuel, lczhmmq, jackson duetting, lczhmmq yu, ring something, yu, duetting ring\n",
      "\n",
      "Topic  10\n",
      "vs thanos, worthy fight, fight ready, go imax, imax worthy, worthy, thanos go, imax, ready, vs\n",
      "\n",
      "Topic  11\n",
      "adidashoop brielarson, okayyy, xvz lrglzw, xvz, co xvz, lrglzw, okayyy adidashoop, brielarson co, adidashoop, brielarson\n",
      "\n",
      "Topic  12\n",
      "avenger endgame, endgame trailer, gunn, trailer, trailer drop, toomuuch, explode heart, cp nd, guardian toomuuch, toomuuch co\n",
      "\n",
      "Topic  13\n",
      "open weekend, weekend higherfurtherfaster, higherfurtherfaster co, higherfurtherfaster, fan, open, weekend, saturday, brielarson pop, pop theater\n",
      "\n",
      "Topic  14\n",
      "larson, brie larson, brie, look brie, thor forget, larson understand, dead family, family look, forget dead, family\n",
      "\n",
      "Topic  15\n",
      "go, slap, definitely go, skin right, right else, slap skin, go slap, skin, thor definitely, definitely\n",
      "\n",
      "Topic  16\n",
      "stan, lee, stan lee, intro, lee co, change, ok, image stan, intro image, ivh\n",
      "\n",
      "Topic  17\n",
      "spoiler, spoiler without, wlzwectivx, co wlzwectivx, context, context co, spoiler context, without, without context, co\n",
      "\n",
      "Topic  18\n",
      "love, chance win, originalfunko, follow originalfunko, originalfunko chance, follow, chance, win, carol, pop\n",
      "\n",
      "Topic  19\n",
      "congrat brielarson, brielarson well, well deserve, wpy, co wpy, deserve co, wpy sveuvf, sveuvf, boom congrat, boom\n"
     ]
    }
   ],
   "source": [
    "nmf_0 = NMF(20)\n",
    "doc_topic_NMF_0 = nmf_0.fit_transform(bag_of_words_0)\n",
    "print(nmf_0.reconstruction_err_)\n",
    "\n",
    "display_topics(nmf_0, tfidf_0.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106.26530968104078\n",
      "\n",
      "Topic  0\n",
      "co fvumqtm, fvumqtm, fvumqtm hj, hj, without context, without, context co, context, co, context pt\n",
      "\n",
      "Topic  1\n",
      "ydfekkjae, co ydfekkjae, thor watch, train pistol, widow train, pistol co, watch black, pistol, train, watch\n",
      "\n",
      "Topic  2\n",
      "want, want home, ftbp utcom, utcom, want war, co ftbp, home want, ftbp, niggas want, bitch niggas\n",
      "\n",
      "Topic  3\n",
      "lczkximxrh, co lczkximxrh, facility endgame, show avenger, endgame co, show, endgame, avenger facility, facility, avenger\n",
      "\n",
      "Topic  4\n",
      "thor battlefield, co ovkuamt, ovkuamt xk, ovkuamt, xk, battlefield co, battlefield, thor, co, thanos thor\n",
      "\n",
      "Topic  5\n",
      "widow fire, facility thor, fire gun, vrq, co vrq, gun avenger, gun, fire, thor co, avenger facility\n",
      "\n",
      "Topic  6\n",
      "business co, tw, thor handle, avenger distract, jvb tw, distract thanos, handle business, jvb, co jvb, wait thor\n",
      "\n",
      "Topic  7\n",
      "mf bitch, mf, bitch, bad bitch, bad, really bitch, woman mf, damn actually, actually drop, mf flex\n",
      "\n",
      "Topic  8\n",
      "worth, worth watch, worth good, worth hype, watch, jbendana give, worth avenger, give worth, jbendana, hype\n",
      "\n",
      "Topic  9\n",
      "samuel jackson, samuel, jackson, larson samuel, yu, duetting, lczhmmq yu, duetting ring, ring something, lczhmmq\n",
      "\n",
      "Topic  10\n",
      "vs thanos, worthy fight, fight ready, go imax, imax worthy, worthy, thanos go, imax, ready, vs\n",
      "\n",
      "Topic  11\n",
      "adidashoop brielarson, lrglzw, xvz, okayyy, okayyy adidashoop, xvz lrglzw, co xvz, brielarson co, adidashoop, brielarson\n",
      "\n",
      "Topic  12\n",
      "avenger endgame, endgame trailer, gunn, trailer, trailer drop, toomuuch, explode heart, cp nd, guardian toomuuch, toomuuch co\n",
      "\n",
      "Topic  13\n",
      "open weekend, weekend higherfurtherfaster, higherfurtherfaster co, higherfurtherfaster, fan, open, weekend, saturday, theater saturday, fan open\n",
      "\n",
      "Topic  14\n",
      "larson, brie larson, brie, look brie, family look, larson understand, thor forget, forget dead, dead family, family\n",
      "\n",
      "Topic  15\n",
      "go, slap, definitely go, skin right, right else, slap skin, go slap, skin, thor definitely, definitely\n",
      "\n",
      "Topic  16\n",
      "stan, lee, stan lee, intro, lee co, change, ok, image stan, intro image, ivh\n",
      "\n",
      "Topic  17\n",
      "spoiler, spoiler without, co wlzwectivx, wlzwectivx, context, context co, spoiler context, without, without context, co\n",
      "\n",
      "Topic  18\n",
      "love, chance win, originalfunko, originalfunko chance, follow originalfunko, follow, chance, win, carol, pop\n",
      "\n",
      "Topic  19\n",
      "congrat brielarson, brielarson well, co wpy, well deserve, wpy sveuvf, wpy, deserve co, sveuvf, boom congrat, boom\n"
     ]
    }
   ],
   "source": [
    "nmf_1 = NMF(20)\n",
    "doc_topic_NMF_1 = nmf_1.fit_transform(bag_of_words_1)\n",
    "print(nmf_1.reconstruction_err_)\n",
    "\n",
    "display_topics(nmf_1, tfidf_1.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568.2097616940998\n",
      "\n",
      "Topic  0\n",
      "htohktois, co htohktois, pop theater, brielarson pop, night surprise, theater saturday, saturday night, fan open, surprise fan, saturday\n",
      "\n",
      "Topic  1\n",
      "ultimate experience, popcorn soda, soda, help fan, fan popcorn, ultimate, popcorn, help, experience, experience brielarson\n",
      "\n",
      "Topic  2\n",
      "studio play, play theater, play, theater ticket, moment studio, wait moment, ticket co, ticket, studio, moment\n",
      "\n",
      "Topic  3\n",
      "image stan, intro image, ivh ok, ivh, co ivh, change intro, image, ok, lee co, intro\n",
      "\n",
      "Topic  4\n",
      "sveuvf, wpy sveuvf, boom congrat, co wpy, well deserve, wpy, brielarson well, boom, deserve co, congrat brielarson\n",
      "\n",
      "Topic  5\n",
      "uylpevb, co uylpevb, intro roll, roll co, roll, intro, co, intro co, logo intro, rcx\n",
      "\n",
      "Topic  6\n",
      "avengersendgame theater, studio avengersendgame, theater april, april co, april, whatev watch, trailer studio, brand trailer, watch brand, ncamd jspp\n",
      "\n",
      "Topic  7\n",
      "uugwmtwqt, co uugwmtwqt, proud co, proud, co, brielarson, congratulation, brielarson proud, power heart, wit brain\n",
      "\n",
      "Topic  8\n",
      "avengersendgame co, avengersendgame, farm avengersendgame, thanos thor, farm, run farm, thor run, oog, oog ypcyc, co oog\n",
      "\n",
      "Topic  9\n",
      "choose, woman, wxaiy, choose star, co wxaiy, choose define, however choose, define choose, wxaiy ef, woman however\n",
      "\n",
      "Topic  10\n",
      "cq ug, ug pivn, pivn, logo change, co cq, change stan, cq, ug, logo, lee co\n",
      "\n",
      "Topic  11\n",
      "context, context co, without context, without, spoiler, fvumqtm, fvumqtm hj, co fvumqtm, hj, spoiler without\n",
      "\n",
      "Topic  12\n",
      "cat, history miss, call cool, cool cat, cat critic, critic call, cat movie, movie history, critic, cool\n",
      "\n",
      "Topic  13\n",
      "tp nt, kkie, nt kkie, nt, co tp, tp, brielarson pop, night surprise, theater saturday, pop theater\n",
      "\n",
      "Topic  14\n",
      "fhpwndnvyx, wakanda across, co fhpwndnvyx, cheer wakanda, across universe, universe brielarson, wakanda, brielarson weekend, cheer, across\n",
      "\n",
      "Topic  15\n",
      "follow originalfunko, originalfunko chance, originalfunko, chance win, chance, follow, win, pop, funkowomenofpower, funkowomenofpower internationalwomensday\n",
      "\n",
      "Topic  16\n",
      "internationalwomensday cast, happy internationalwomensday, internationalwomensday, cast, happy, co qz, qz, cast co, cast studio, studio co\n",
      "\n",
      "Topic  17\n",
      "brielarson samuelljackson, samuelljackson, test, app co, watch free, carpoolkaraoke, arianagrande, appletv app, free appletv, appletv\n",
      "\n",
      "Topic  18\n",
      "studio movie, movie world, world, ticket, studio, ticket co, co ulr, ulr, world theater, movie\n",
      "\n",
      "Topic  19\n",
      "box, box office, office, co, film, opening, weekend, female, million, time\n"
     ]
    }
   ],
   "source": [
    "nmf_2 = NMF(20)\n",
    "doc_topic_NMF_2 = nmf_2.fit_transform(bag_of_words_2)\n",
    "print(nmf_2.reconstruction_err_)\n",
    "\n",
    "display_topics(nmf_2, tfidf_2.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177.25178740857922\n",
      "\n",
      "Topic  0\n",
      "yxxpsg co, yxxpsg, co wjebx, co yxxpsg, wjebx qp, wjebx, qp, captainmarvelxboxsweepstake nopurchnec, xbox captainmarvelxboxsweepstake, captainmarvelxboxsweepstake\n",
      "\n",
      "Topic  1\n",
      "mkgxe, co mkgxe, funkowomenofpower co, motorcycle pop, danver motorcycle, win carol, pop ride, ride funkowomenofpower, motorcycle, ride\n",
      "\n",
      "Topic  2\n",
      "box, sh vfhn, co qvshhlrzh, vfhn co, vfhn, qvshhlrzh, co sh, sh, order mcc, box close\n",
      "\n",
      "Topic  3\n",
      "lwzcakbfsy, co lwzcakbfsy, win walmart, walmart exclusive, walmart, exclusive pop, pop co, exclusive, pop, originalfunko chance\n",
      "\n",
      "Topic  4\n",
      "kne wtrgxd, wtrgxd, co kne, kne, pop goosethecat, cat pop, win goose, goosethecat co, goosethecat, goose cat\n",
      "\n",
      "Topic  5\n",
      "uxvbxgpunv, co uxvbxgpunv, pop funkowomenofpower, win chase, chase pop, chase, funkowomenofpower internationalwomensday, internationalwomensday co, internationalwomensday, funkowomenofpower\n",
      "\n",
      "Topic  6\n",
      "co nkyuxukvwf, nkyuxukvwf, korath pop, pop funkoeccc, exclusive korath, win eccc, funkoeccc co, eccc exclusive, funkoeccc, korath\n",
      "\n",
      "Topic  7\n",
      "exclusive pack, pack dorbz, dorbz bundle, funko shop, bundle funkowomenofpower, shop exclusive, csl jgehy, csl, co csl, jgehy\n",
      "\n",
      "Topic  8\n",
      "box, iv sbsa, sbsa, ok gm, sbsa jm, jm co, co iv, iv, co ok, gm\n",
      "\n",
      "Topic  9\n",
      "marveluk winner, correct answer, answer chance, reply correct, captainmarvelxboxsweepstak marveluk, follow reply, xbox captainmarvelxboxsweepstak, correct, captainmarvelxboxsweepstak, announce march\n",
      "\n",
      "Topic  10\n",
      "iszekchfk, co iszekchfk, motorcycle pop, danver motorcycle, win carol, pop ride, ride funkowomenofpower, motorcycle, ride, carol danver\n",
      "\n",
      "Topic  11\n",
      "co klyqcd, co qyfcmliltm, qyfcmliltm, jnd co, klyqcd, utlz rule, utlz, ci utlz, klyqcd jnd, sg ci\n",
      "\n",
      "Topic  12\n",
      "ccokpkxvcs, co ccokpkxvcs, ccokpkxvcs co, yl id, id qw, id, captainmarvelxboxcont nopurchnec, xbox captainmarvelxboxcont, qw, captainmarvelxboxcont\n",
      "\n",
      "Topic  13\n",
      "originalfunko prize, win originalfunko, talos goose, ver talos, pack ver, co saxlbpz, cat mystery, mystery character, saxlbpz, saxlbpz co\n",
      "\n",
      "Topic  14\n",
      "away set, figure follow, set marvellegend, marvellegend figure, country welcome, welcome winner, win country, winner dm, dm co, marvellegend\n",
      "\n",
      "Topic  15\n",
      "co ipdn, fyjv qx, ipdn, ipdn gi, fyjv, co fyjv, gi co, gi, qx, cs co\n",
      "\n",
      "Topic  16\n",
      "win gitd, co fqujk, fqujk, fqujk zc, gitd walmart, gitd, zc, follow chance, walmart exclusive, walmart\n",
      "\n",
      "Topic  17\n",
      "qv wuiojhc, tygvbtxmh, co khkdfoazso, khkdfoazso rule, khkdfoazso, wuiojhc, captainmarvelimaxprizegiveaway chance, co tygvbtxmh, retweet captainmarvelimaxprizegiveaway, wuiojhc co\n",
      "\n",
      "Topic  18\n",
      "competition, enter, uk, funko pop, weekend, retweet, bag, open, bundle, funko\n",
      "\n",
      "Topic  19\n",
      "kitty, appeal superhero, goose humanizing, humanizing appeal, pet goosethecat, icymi kitty, humanizing, kitty kitty, superhero pet, kitty goose\n"
     ]
    }
   ],
   "source": [
    "nmf_3 = NMF(20)\n",
    "doc_topic_NMF_3 = nmf_3.fit_transform(bag_of_words_3)\n",
    "print(nmf_3.reconstruction_err_)\n",
    "\n",
    "display_topics(nmf_3, tfidf_3.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420.9617840379525\n",
      "\n",
      "Topic  0\n",
      "model draw, draw xd, xd enjoy, since star, credit sailor, moon role, ohfhak, co ohfhak, brielarson credit, star brielarson\n",
      "\n",
      "Topic  1\n",
      "co ykreclow, ykreclow, brielarson president, president co, president, brielarson, co, brielarson co, co pjfmhvhnzc, pjfmhvhnzc\n",
      "\n",
      "Topic  2\n",
      "war, overpopulation scarce, operation homecoming, scarce resource, ragnarok historical, revisionism winter, terrorism ragnarok, war overpopulation, military operation, unemployment infinity\n",
      "\n",
      "Topic  3\n",
      "hvuzhv, xwhbaqfvw, motherfuck love, co hvuzhv, co xwhbaqfvw, hvuzhv co, motherfuck, love samuel, jackson co, samuel jackson\n",
      "\n",
      "Topic  4\n",
      "hijab marvelstudios, design hijab, xdlktuc, co xdlktuc, marvelstudios badass, decide design, hero high, badass hero, hijab, faster co\n",
      "\n",
      "Topic  5\n",
      "reference, movie, shout part, marvelstudio friend, spend reference, therealstanlee shout, mess lifetime, friend therealstanlee, universe survive, lifetime spend\n",
      "\n",
      "Topic  6\n",
      "hashtag, cat background, click hashtag, korea trend, background click, um korea, hashtag welcome, hashtag goose, trend hashtag, goose people\n",
      "\n",
      "Topic  7\n",
      "co htnzqx, htnzqx nvc, movie juicy, htnzqx, jumpsuit fucking, nvc, fucking power, power move, juicy jumpsuit, jumpsuit\n",
      "\n",
      "Topic  8\n",
      "dg fdo, fan kid, fdo, time comic, co dg, amazing time, kid co, dg, comic fan, kid\n",
      "\n",
      "Topic  9\n",
      "go flop, flop half, lhhrs bud, billi less, co lhhrs, half billi, lhhrs, people film, billi, feel people\n",
      "\n",
      "Topic  10\n",
      "first, movie, man, opening top, movi first, top first, movie pander, movie spider, pander sjws, man movi\n",
      "\n",
      "Topic  11\n",
      "weekend higherfurtherfaster, open weekend, higherfurtherfaster co, higherfurtherfaster, open, fan, weekend, pop theater, theater saturday, night surprise\n",
      "\n",
      "Topic  12\n",
      "bez jqox, jqox, bez, co bez, world fragile, grateful introduce, introduce world, fragile male, male movie, movie review\n",
      "\n",
      "Topic  13\n",
      "yes amazing, co vuzexoyxs, vuzexoyxs, amazing obsession, obsession cat, obsession, cat goose, goose co, yes, goose\n",
      "\n",
      "Topic  14\n",
      "role enjoy, cvqhchsic, captainjaneway, captainjaneway two, today warp, warp speed, two save, brielarson trailblaz, galaxy good, co cvqhchsic\n",
      "\n",
      "Topic  15\n",
      "boom congrat, sveuvf, wpy sveuvf, wpy, co wpy, well deserve, brielarson well, deserve co, boom, congrat brielarson\n",
      "\n",
      "Topic  16\n",
      "woman, every, trade write, woman bridesmaid, write never, bridesmaid pitch, trip consumer, happen stop, consumer prove, well trade\n",
      "\n",
      "Topic  17\n",
      "ww, love gorgeous, yuxwhhlz, samoanjyandall co, co yuxwhhlz, whole ww, congratulation team, crew wish, gorgeous piece, ww crew\n",
      "\n",
      "Topic  18\n",
      "fleck co, boden ryan, dir, dir anna, ryan fleck, fleck, ryan, anna boden, boden, cxoqhhdmfv\n",
      "\n",
      "Topic  19\n",
      "co jrnhi, owu, jrnhi, jrnhi owu, yes go, go brielarson, butt co, kick butt, butt, brielarson kick\n"
     ]
    }
   ],
   "source": [
    "nmf_4 = NMF(20)\n",
    "doc_topic_NMF_4 = nmf_4.fit_transform(bag_of_words_4)\n",
    "print(nmf_4.reconstruction_err_)\n",
    "\n",
    "display_topics(nmf_4, tfidf_4.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110.3096285597803\n",
      "\n",
      "Topic  0\n",
      "head avengersendgame, rws, aim, co rws, never aim, thor never, flinch thor, aim head, flinch, head\n",
      "\n",
      "Topic  1\n",
      "ybavku, co ybavku, scar co, scar, co, goosethecat, goosethecat co, brielarson, meow, zpumpa\n",
      "\n",
      "Topic  2\n",
      "avenger iron, iron, iron man, man, avenger, thor, hulk ironman, order america, movie chronological, thor dark\n",
      "\n",
      "Topic  3\n",
      "rnuixscvsh, inspire logo, mavel, mavel inspire, co rnuixscvsh, logo co, inspire, logo, co, pivn\n",
      "\n",
      "Topic  4\n",
      "co py, summarize, eh yk, py eh, summarize video, py, eh, yk, video co, video\n",
      "\n",
      "Topic  5\n",
      "jb, gsc paradigm, paradigm, hall movie, gsc, hall, seat, paradigm mall, time seat, mall jb\n",
      "\n",
      "Topic  6\n",
      "co xrlaxmo, loyal bestie, loyal, bestie co, xrlaxmo, bestie, co, goosethecat, goosethecat co, brielarson\n",
      "\n",
      "Topic  7\n",
      "leave credit, already st, rvkp, pyqrf, pyqrf rvkp, still people, co pyqrf, movie yet, yet still, people leave\n",
      "\n",
      "Topic  8\n",
      "fury singing, mmmi, co mmmi, never nick, mmmi bct, bct, ring co, singing ring, singing, nick fury\n",
      "\n",
      "Topic  9\n",
      "kiky cat, jxn, kiky, co jxn, jxn eu, cat flerken, eu, flerken co, flerken, cat\n",
      "\n",
      "Topic  10\n",
      "likz, studio retweet, fast secure, tweet captainmarvelmy, co gjps, gjps likz, gjps, retweet tweet, secure ticket, captainmarvelmy co\n",
      "\n",
      "Topic  11\n",
      "tribute co, qmfuyee, co qmfuyee, kind spoiler, spoiler stan, lee tribute, kind, tribute, lee, stan lee\n",
      "\n",
      "Topic  12\n",
      "gentleman thanos, thanos shake, tp rx, lady gentleman, shake co, gentleman, rx, shake, lady, co tp\n",
      "\n",
      "Topic  13\n",
      "without context, context, context co, without, fvumqtm hj, co fvumqtm, fvumqtm, hj, spoiler without, co fzesbwid\n",
      "\n",
      "Topic  14\n",
      "iron, iron man, man, mengikut kronologi, mengikut, senarai, senarai movie, movie mengikut, kronologi oleh, feige president\n",
      "\n",
      "Topic  15\n",
      "many feat, feat road, sky studio, brielarson sky, become watch, road become, road, cinema ticket, sky, feat\n",
      "\n",
      "Topic  16\n",
      "watch co, thanos watch, co kerqvlz, ry, kerqvlz, kerqvlz ry, watch, thanos, co, co niwm\n",
      "\n",
      "Topic  17\n",
      "crcalrzofi, co crcalrzofi, spoiler co, spoiler, co, spoiler without, post credit, post, co fzesbwid, fzesbwid\n",
      "\n",
      "Topic  18\n",
      "winner submit, week winner, congrat tylorhepner, timelapse drawing, bsdoh iuio, ibl, gamora timelapse, submit video, famous co, become gagfunoff\n",
      "\n",
      "Topic  19\n",
      "end, end game, game, woi, tak, thanos, avenger end, end credit, pun tak, trailer end\n"
     ]
    }
   ],
   "source": [
    "nmf_5 = NMF(20)\n",
    "doc_topic_NMF_5 = nmf_5.fit_transform(bag_of_words_5)\n",
    "print(nmf_5.reconstruction_err_)\n",
    "\n",
    "display_topics(nmf_5, tfidf_5.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234.55316232497648\n",
      "\n",
      "Topic  0\n",
      "woman immediately, room seem, win tolerate, patronizing counterproductive, seem patronizing, kind bigotry, son come, tolerate kind, celebrate utterly, counterproductive celebrate\n",
      "\n",
      "Topic  1\n",
      "monologue, monologue rlm, ivjzzu, df ivjzzu, review perfection, rlm review, opening monologue, perfection co, co df, rlm\n",
      "\n",
      "Topic  2\n",
      "troop, thank, live american, join thank, thank card, name thank, troop real, hi samuel, back join, troop add\n",
      "\n",
      "Topic  3\n",
      "critic, movie, afraid hate, pzyk, critic tailor, fit social, co pzyk, lie happy, internationalwomensday female, tailor\n",
      "\n",
      "Topic  4\n",
      "nuke, pic, audience, review, morning pic, pic right, abysmally, co lhjglexldv, mass nuke, right minute\n",
      "\n",
      "Topic  5\n",
      "un thinly, leader kim, caucasian woman, base real, jong, jong un, western film, disguise caucasian, thinly disguise, exploit supreme\n",
      "\n",
      "Topic  6\n",
      "plot, go regret, hole many, give poorly, write jumpy, plot plot, contrivance, plot contrivance, regret movie, many plot\n",
      "\n",
      "Topic  7\n",
      "trump, supporter complicit, complicit, trump supporter, supporter, right historic, gz fs, jackson despise, oppose trump, ha gz\n",
      "\n",
      "Topic  8\n",
      "murder, parent, baseball little, tell baseball, destroy last, superman entire, planet destroy, batman parent, baseball, uncle\n",
      "\n",
      "Topic  9\n",
      "wonderwoman co, wonderwoman, co hpdxnbrqjg, hpdxnbrqjg, good wonderwoman, good, co, strong wonderwoman, co bnmjkhcbzb, bnmjkhcbzb\n",
      "\n",
      "Topic  10\n",
      "co dwvkimsqxh, dwvkimsqxh, woman co, wonder woman, wonder, woman, co, woman racist, racist, man\n",
      "\n",
      "Topic  11\n",
      "popcorn drink, narrative really, delivery absolutely, atrocious also, absolutely atrocious, save popcorn, also push, drink terrible, pig narrative, role line\n",
      "\n",
      "Topic  12\n",
      "result, search, search term, worthy search, boost top, top search, review recategoriz, medium channel, result authoritative, channel artificially\n",
      "\n",
      "Topic  13\n",
      "important, lead, super important, important success, success female, overlook billion, vcyqsjf, franchise lead, jovovich important, movie overlook\n",
      "\n",
      "Topic  14\n",
      "gt, complete confidence, gt close, course shazam, opinion course, film complete, shazam gt, confidence opinion, confidence, complete\n",
      "\n",
      "Topic  15\n",
      "boycott, alita, battle angel, alita battle, angel, jack posobiec, posobiec, battle, jack, alitachallenge\n",
      "\n",
      "Topic  16\n",
      "call, people progressive, show roseanne, roseanne entertain, brainwash sell, sell pretty, liberal show, entertain guy, progressive attack, feminist brainwash\n",
      "\n",
      "Topic  17\n",
      "fighter pilot, fighter, pilot, female, female fighter, jeannie, jeannie leavitt, leavitt, usairforce first, brig gen\n",
      "\n",
      "Topic  18\n",
      "rotten, co, tomato, rotten tomato, review, delete, tomato delete, movie, still, mizcdzbbez\n",
      "\n",
      "Topic  19\n",
      "corny ass, open international, woman corny, realize open, ass shit, corny, international woman, international, realize, ass\n"
     ]
    }
   ],
   "source": [
    "nmf_6 = NMF(20)\n",
    "doc_topic_NMF_6 = nmf_6.fit_transform(bag_of_words_6)\n",
    "print(nmf_6.reconstruction_err_)\n",
    "\n",
    "display_topics(nmf_6, tfidf_6.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.656090065763465\n",
      "\n",
      "Topic  0\n",
      "really, boring bland, want boring, jackson cat, bland sam, cat really, really want, sam jackson, sam, boring\n",
      "\n",
      "Topic  1\n",
      "op love, damn excited, time theater, badass post, total badass, endgame time, dawg op, scene damn, love total, excited go\n",
      "\n",
      "Topic  2\n",
      "unpopular opinion, unpopular, opinion wonder, opinion, woman good, wonder woman, wonder, woman, good, woman gt\n",
      "\n",
      "Topic  3\n",
      "movie, tl dr, tl, leftish, magic, movie half, landmark, half decent, leftish trash, propaganda brainwashing\n",
      "\n",
      "Topic  4\n",
      "sneezing, co kceihtpkop, kceihtpkop, sneezing co, co, studio, context, context co, co uugwmtwqt, proud co\n",
      "\n",
      "Topic  5\n",
      "awesome, awesome fact, jpyo jyppa, jpyo, jyppa, co jpyo, awesome co, awesome end, wait, fact\n",
      "\n",
      "Topic  6\n",
      "ultimate duo, thor ultimate, dawg thor, duo watch, time hour, trailer time, watch trailer, duo, hour, trailer\n",
      "\n",
      "Topic  7\n",
      "bar, fury, fqgd, hawkeye recreate, fury converse, bar bud, sl, bar nick, converse, yes actual\n",
      "\n",
      "Topic  8\n",
      "fantastic, old, afternoon, lan start, tomorrow afternoon, fantastic meal, start tomorrow, sleep, lan, wife fantastic\n",
      "\n",
      "Topic  9\n",
      "guy, male pig, assume guy, lmao sexist, guy lmao, honest assume, sexist male, assume, pig, lmao\n",
      "\n",
      "Topic  10\n",
      "good, love good, good movie, film, movie, alright good, alright, nothing, crazy decent, nothing crazy\n",
      "\n",
      "Topic  11\n",
      "two daughter, thanos trouble, time two, twice weekend, daughter thanos, trouble, second time, weekend second, twice, daughter\n",
      "\n",
      "Topic  12\n",
      "far origin, though really, real though, movie real, imagine leave, smash avenger, leave cinema, cinema credit, fun far, credit movie\n",
      "\n",
      "Topic  13\n",
      "random, stiff throat, good theater, random today, today feel, note go, random note, night bad, hurt random, neck stiff\n",
      "\n",
      "Topic  14\n",
      "open weekend, weekend higherfurtherfaster, higherfurtherfaster co, higherfurtherfaster, open, fan, pop theater, fan open, surprise fan, surprise\n",
      "\n",
      "Topic  15\n",
      "co fdnmqeiiy, popular fact, fdnmqeiiy, fact wonder, good co, popular, fact, woman, wonder woman, wonder\n",
      "\n",
      "Topic  16\n",
      "ehlo, ehlo rp, entire goonsquad, co kf, kf, goonsquad co, kf ehlo, goonsquad, rp, entire\n",
      "\n",
      "Topic  17\n",
      "feel, start feel, cool good, first feel, feel familiar, familiar cool, familiar, really first, bad start, good job\n",
      "\n",
      "Topic  18\n",
      "night pal, home cook, cook meal, cook, fantastic great, gym session, today fantastic, good vibe, gym, pal lt\n",
      "\n",
      "Topic  19\n",
      "wpy sveuvf, wpy, congrat brielarson, co wpy, deserve co, sveuvf, boom congrat, boom, well deserve, brielarson well\n"
     ]
    }
   ],
   "source": [
    "nmf_7 = NMF(20)\n",
    "doc_topic_NMF_7 = nmf_7.fit_transform(bag_of_words_7)\n",
    "print(nmf_7.reconstruction_err_)\n",
    "\n",
    "display_topics(nmf_7, tfidf_7.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.67483560150584\n",
      "\n",
      "Topic  0\n",
      "parent basement, move parent, female next, basement, next move, parent, next, move, female, movie\n",
      "\n",
      "Topic  1\n",
      "date love, love favorite, favorite part, uhhh, marveling, sweat, sweat uhhh, part sweat, uhhh marveling, favorite\n",
      "\n",
      "Topic  2\n",
      "pound, dude neckbeard, bunch pound, whether go, bad idk, good hand, neckbeard bad, pound dude, go review, hand bunch\n",
      "\n",
      "Topic  3\n",
      "without cheeto, burp, glad neckbeard, neckbeard boycott, actually glad, boycott nice, dust burp, watch superhero, movie without, nice watch\n",
      "\n",
      "Topic  4\n",
      "whip, wildly lady, fun head, lady hear, head whip, whip wildly, wildly, head, hear, lady\n",
      "\n",
      "Topic  5\n",
      "embarrassing nightmare, corporate slop, nightmare everyone, letter medium, nightmare, thank world, social justice, social, weirdo thank, world embarrassing\n",
      "\n",
      "Topic  6\n",
      "aadmi, kaam na, kare kuch, keep drop, badla, badla open, kuch, kuch bus, everyday matlab, everyday\n",
      "\n",
      "Topic  7\n",
      "ask, bohemian, rhapsody, headphone, ask bohemian, bohemian rhapsody, international, woman, international woman, headphone wait\n",
      "\n",
      "Topic  8\n",
      "sneaker, today sneaker, celebration, celebration good, shin celebration, sun shin, shin, sun, layer today, layer\n",
      "\n",
      "Topic  9\n",
      "never, movie, movie dd, cool power, handsome little, star movie, understand father, handsome, kree retcon, implication\n",
      "\n",
      "Topic  10\n",
      "watch, watch watch, trooper, scene starship, watch part, part scene, starship trooper, trooper hour, starship, hour loop\n",
      "\n",
      "Topic  11\n",
      "kick ass, kick, ass, prefer, edge contemporary, contemporary rock, seem livin, music quaint, sing planet, quaint prefer\n",
      "\n",
      "Topic  12\n",
      "publication, ad, usaf base, personnel co, force run, god mkhut, mkhut, run ad, co god, yous\n",
      "\n",
      "Topic  13\n",
      "co, co xwhbaqfvw, co hvuzhv, motherfuck love, hvuzhv co, motherfuck, love samuel, jackson co, xwhbaqfvw, hvuzhv\n",
      "\n",
      "Topic  14\n",
      "happy brie, activism bux, bux weekend, larson million, bux, million political, political activism, million, activism, larson\n",
      "\n",
      "Topic  15\n",
      "murca, ihhh, ihhh caaahh, merr, ahhh merr, merr ihhh, ahhh, caaahh, america, caaahh yes\n",
      "\n",
      "Topic  16\n",
      "finally, woman look, finally talk, manager, look finally, talk manager, white woman, talk, woman, white\n",
      "\n",
      "Topic  17\n",
      "cat, interrogate, interrogate cat, naturally interrogate, naturally, nice cat, nice, go cat, go, goose\n",
      "\n",
      "Topic  18\n",
      "book, promote, comic book, comic, base, book movie, much promotion, shen yun, yun, promotion comic\n",
      "\n",
      "Topic  19\n",
      "fucking good, fucking, good, movie, far, movie far, good break, ground dare, ground, force also\n"
     ]
    }
   ],
   "source": [
    "nmf_11 = NMF(20)\n",
    "doc_topic_NMF_11 = nmf_11.fit_transform(bag_of_words_11)\n",
    "print(nmf_11.reconstruction_err_)\n",
    "\n",
    "display_topics(nmf_11, tfidf_11.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.841353650513895\n",
      "\n",
      "Topic  0\n",
      "something co, lczhmmq yu, lczhmmq, duetting ring, duetting, yu, jackson duetting, ring something, co lczhmmq, larson samuel\n",
      "\n",
      "Topic  1\n",
      "context co, context, without context, hj, co fvumqtm, fvumqtm, fvumqtm hj, without, co, spoiler\n",
      "\n",
      "Topic  2\n",
      "surprise fan, saturday night, theater saturday, night surprise, fan open, pop theater, brielarson pop, surprise, saturday, weekend higherfurtherfaster\n",
      "\n",
      "Topic  3\n",
      "nine inch, inch, inch nail, nail shirt, nail, nine, offensive pandering, answer deeply, sue scene, garbage play\n",
      "\n",
      "Topic  4\n",
      "absolutely brie, co otrizk, larson slander, otrizk asd, asd, otrizk, slander timeline, timeline co, slander, timeline\n",
      "\n",
      "Topic  5\n",
      "originalfunko, originalfunko chance, follow originalfunko, chance win, chance, follow, win, pop, funkowomenofpower, funkowomenofpower internationalwomensday\n",
      "\n",
      "Topic  6\n",
      "cool, time, really show, time also, also thank, boyfriend cool, mkgjpsyofn co, th time, nsfokb, cool buy\n",
      "\n",
      "Topic  7\n",
      "go, wanna, go watch, want go, go go, wanna go, want, tonight, tomorrow, go tomorrow\n",
      "\n",
      "Topic  8\n",
      "box, box office, office, lashanalynch co, check interview, lashanalynch, check, office million, exf, exf co\n",
      "\n",
      "Topic  9\n",
      "soda, fan popcorn, popcorn soda, ultimate experience, popcorn, help fan, ultimate, experience, experience brielarson, brielarson help\n",
      "\n",
      "Topic  10\n",
      "stan, stan lee, lee, lee cameo, cameo, cameo co, co hg, hg zb, feel watch, last stan\n",
      "\n",
      "Topic  11\n",
      "good, really good, movie, good movie, pretty, time, film, pretty good, honestly, ever\n",
      "\n",
      "Topic  12\n",
      "shuh xh, shuh, co shuh, xh cm, xh, cm, review co, review, finally, finally review\n",
      "\n",
      "Topic  13\n",
      "scene co, scene, last night, viyvsvg, co viyvsvg, far favorite, night far, favorite scene, far, favorite\n",
      "\n",
      "Topic  14\n",
      "watch, cinema, go watch, still, must, still watch, watch go, must still, go hype, hype cinema\n",
      "\n",
      "Topic  15\n",
      "really, bitch, really bitch, really good, thanos, really want, pity, combination, good pity, pity fight\n",
      "\n",
      "Topic  16\n",
      "amazing, legit amazing, legit, movie, everything, fuck, stop amazing, still stop, amazing go, stop\n",
      "\n",
      "Topic  17\n",
      "ticket, someone, pls, buy ticket, ticket pls, someone buy, buy, studio, theater, movie\n",
      "\n",
      "Topic  18\n",
      "love, brielarson, love brie, love brielarson, brielarson love, movie, brielarson co, love co, larson, brie\n",
      "\n",
      "Topic  19\n",
      "woman, international woman, international, release international, release, woman mood, mood, choose, happy, happy international\n"
     ]
    }
   ],
   "source": [
    "nmf_15 = NMF(20)\n",
    "doc_topic_NMF_15 = nmf_15.fit_transform(bag_of_words_15)\n",
    "print(nmf_15.reconstruction_err_)\n",
    "\n",
    "display_topics(nmf_15, tfidf_15.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/nmf_marvel/nmf_0.pickle', 'wb') as to_write:\n",
    "    pickle.dump(nmf_0, to_write)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/nmf_marvel/nmf_1.pickle', 'wb') as to_write:\n",
    "    pickle.dump(nmf_1, to_write)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/nmf_marvel/nmf_2.pickle', 'wb') as to_write:\n",
    "    pickle.dump(nmf_2, to_write)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/nmf_marvel/nmf_3.pickle', 'wb') as to_write:\n",
    "    pickle.dump(nmf_3, to_write)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/nmf_marvel/nmf_4.pickle', 'wb') as to_write:\n",
    "    pickle.dump(nmf_4, to_write)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/nmf_marvel/nmf_5.pickle', 'wb') as to_write:\n",
    "    pickle.dump(nmf_5, to_write)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/nmf_marvel/nmf_6.pickle', 'wb') as to_write:\n",
    "    pickle.dump(nmf_6, to_write)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/nmf_marvel/nmf_7.pickle', 'wb') as to_write:\n",
    "    pickle.dump(nmf_7, to_write)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/nmf_marvel/nmf_11.pickle', 'wb') as to_write:\n",
    "    pickle.dump(nmf_11, to_write)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_5/topic_modeling/nmf_marvel/nmf_15.pickle', 'wb') as to_write:\n",
    "    pickle.dump(nmf_15, to_write)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running Topic Modeling on ALL text data, both NMF and LSA, on various topic counts, to feed into DBScan / KMeans for cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Creating list of the processed text files to merge, so it's all in the same format and can re-use code\n",
    "# dfs_to_merge = [df_0, df_1, df_2, df_3, df_4, df_5, df_6, df_7, df_8, df_9, df_10, df_11, df_26, df_40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total = 0\n",
    "\n",
    "# for df in dfs_to_merge:\n",
    "#     print(df.shape)\n",
    "#     total += df.shape[0]\n",
    "    \n",
    "# print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_preprocessed = pd.concat(dfs_to_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_all_preprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all = df_all_preprocessed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/robertpagano/metis_data/project_5/community_pickles_pre_nlp/preprocessed_dfs/df_all.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(df_all, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/robertpagano/metis_data/project_5/community_pickles_pre_nlp/preprocessed_dfs/df_all.pickle', 'rb') as f:\n",
    "#     df_all = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the concat worked, the # of rows equals the number of all the rows added up (just to be safe)\n",
    "\n",
    "Now I'll run a few different LSAs and NMFs on the total data, and move on to clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Text - for both LSA and NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Can come back to tweek this if I notice anything\n",
    "# tweet_stopwords = stopwords.words('english') + \\\n",
    "#     ['rt', 'https', 'http', 'amp', 'via', 'one', 'around', 'would', 'let', 'could', 'going', 'like', \n",
    "#      'get', 'may', 'says', 'say', 'make', 'based', 'even', 'another', 'completely', 'thanks', 'way', \n",
    "#      'find', 'used', 'thing', '2019', 'see', 'need', 'know', 'knows', 'think', 'thinks', 'take', 'new', \n",
    "#      'day', 'days', 'aoc', 'alexandria', 'ocasio', 'cortez', 'ocasio-cortez', 'pron']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_all = TfidfVectorizer(stop_words=tweet_stopwords, token_pattern=\"\\\\b[a-z][a-z]+\\\\b\", ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_all = df_all['tweet_processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag_of_words_all = tfidf_all.fit_transform(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(bag_of_words_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA on all text\n",
    "*10, 15, 20, 25 topics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LSA on 10 topics\n",
    "# lsa_all_10 = TruncatedSVD(10)\n",
    "# lsa_all_10.fit_transform(bag_of_words_all)\n",
    "# lsa_all_10.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display_topics(lsa_all_10, tfidf_all.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/robertpagano/metis_data/project_5/topic_modeling/lsa_aoc/lsa_all_10.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(lsa_all_10, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LSA on 15 topics\n",
    "# lsa_all_15 = TruncatedSVD(15)\n",
    "# lsa_all_15.fit_transform(bag_of_words_all)\n",
    "# lsa_all_15.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_topics(lsa_all_15, tfidf_all.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/robertpagano/metis_data/project_5/topic_modeling/lsa_aoc/lsa_all_15.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(lsa_all_15, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LSA on 20 topics\n",
    "# lsa_all_20 = TruncatedSVD(20)\n",
    "# lsa_all_20.fit_transform(bag_of_words_all)\n",
    "# lsa_all_20.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_topics(lsa_all_20, tfidf_all.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/robertpagano/metis_data/project_5/topic_modeling/lsa_aoc/lsa_all_20.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(lsa_all_20, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LSA on 25 topics\n",
    "# lsa_all_25 = TruncatedSVD(25)\n",
    "# lsa_all_25.fit_transform(bag_of_words_all)\n",
    "# lsa_all_25.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_topics(lsa_all_25, tfidf_all.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/robertpagano/metis_data/project_5/topic_modeling/lsa_aoc/lsa_all_25.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(lsa_all_25, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF on all text\n",
    "*10, 15, 20, 25 topics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NMF on 10 topics\n",
    "# nmf_all_10 = NMF(10)\n",
    "# nmf_all_10.fit_transform(bag_of_words_all)\n",
    "# print(nmf_all_10.reconstruction_err_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_topics(nmf_all_10, tfidf_all.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/robertpagano/metis_data/project_5/topic_modeling/nmf_aoc/nmf_all_10.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(nmf_all_10, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NMF on 15 topics\n",
    "# nmf_all_15 = NMF(15)\n",
    "# nmf_all_15.fit_transform(bag_of_words_all)\n",
    "# print(nmf_all_15.reconstruction_err_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_topics(nmf_all_15, tfidf_all.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/robertpagano/metis_data/project_5/topic_modeling/nmf_aoc/nmf_all_15.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(nmf_all_15, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NMF on 20 topics\n",
    "# nmf_all_20 = NMF(20)\n",
    "# nmf_all_20.fit_transform(bag_of_words_all)\n",
    "# print(nmf_all_20.reconstruction_err_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_topics(nmf_all_20, tfidf_all.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/robertpagano/metis_data/project_5/topic_modeling/nmf_aoc/nmf_all_20.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(nmf_all_20, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NMF on 25 topics\n",
    "# nmf_all_25 = NMF(25)\n",
    "# nmf_all_25.fit_transform(bag_of_words_all)\n",
    "# print(nmf_all_25.reconstruction_err_)\n",
    "\n",
    "# ## setting a variable to the fit transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nmf_model_25_df = pd.DataFrame(data=nmf_all_25.fit_transform(bag_of_words_all))\n",
    "# nmf_model_25_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(nmf_all_25.reconstruction_err_)\n",
    "# nmf_model_25_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE TO SELF - if the above works, I'll need to make DFs of all versions again (which will take around another hour) :(\n",
    "\n",
    "Then I'll concat them with index and screen name, so I can assign values back to the tweeters otherwise. One annoying thing is I didn't pass in tweet ID so I'll have to think about that too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_topics(nmf_all_25, tfidf_all.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/robertpagano/metis_data/project_5/topic_modeling/nmf_aoc/nmf_all_25.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(nmf_all_25, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will create DF's where I append this info to a dataframe\n",
    "\n",
    "then try dbscan with these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_topic_base = df_all.reset_index()\n",
    "# df_topic_base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crap - now I know why I saved the fit_transform(bag_of_words_ objects previously, that's what I need to use to create the df. For now I'm seeing if I can just call that as the \"data\" and see if that works. Otherwise I will need to set them all equal to variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_topic_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsa_all_10 = TruncatedSVD(10)\n",
    "\n",
    "# lsa_model_10_df = pd.DataFrame(data=lsa_all_10.fit_transform(bag_of_words_all))\n",
    "# lsa_model_10_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsa_all_15 = TruncatedSVD(15)\n",
    "\n",
    "# lsa_model_15_df = pd.DataFrame(data=lsa_all_15.fit_transform(bag_of_words_all))\n",
    "# lsa_model_15_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsa_all_20 = TruncatedSVD(20)\n",
    "\n",
    "# lsa_model_20_df = pd.DataFrame(data=lsa_all_20.fit_transform(bag_of_words_all))\n",
    "# lsa_model_20_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsa_all_25 = TruncatedSVD(25)\n",
    "\n",
    "# lsa_model_25_df = pd.DataFrame(data=lsa_all_25.fit_transform(bag_of_words_all))\n",
    "# lsa_model_25_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lsa_model_10 = pd.merge(df_topic_base, lsa_model_10_df, left_index=True, right_index=True)\n",
    "# df_lsa_model_15 = pd.merge(df_topic_base, lsa_model_15_df, left_index=True, right_index=True)\n",
    "# df_lsa_model_20 = pd.merge(df_topic_base, lsa_model_20_df, left_index=True, right_index=True)\n",
    "# df_lsa_model_25 = pd.merge(df_topic_base, lsa_model_25_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nmf_all_10 = NMF(10)\n",
    "\n",
    "# nmf_model_10_df = pd.DataFrame(data=nmf_all_10.fit_transform(bag_of_words_all))\n",
    "# nmf_model_10_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nmf_all_15 = NMF(15)\n",
    "\n",
    "# nmf_model_15_df = pd.DataFrame(data=nmf_all_15.fit_transform(bag_of_words_all))\n",
    "# nmf_model_15_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nmf_all_20 = NMF(20)\n",
    "\n",
    "# nmf_model_20_df = pd.DataFrame(data=nmf_all_20.fit_transform(bag_of_words_all))\n",
    "# nmf_model_20_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # nmf_model_25_df = pd.DataFrame(data=nmf_all_25.fit_transform(bag_of_words_all)) ALREADY DONE!\n",
    "# nmf_model_25_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_nmf_model_10 = pd.merge(df_topic_base, nmf_model_10_df, left_index=True, right_index=True)\n",
    "# df_nmf_model_15 = pd.merge(df_topic_base, nmf_model_15_df, left_index=True, right_index=True)\n",
    "# df_nmf_model_20 = pd.merge(df_topic_base, nmf_model_20_df, left_index=True, right_index=True)\n",
    "# df_nmf_model_25 = pd.merge(df_topic_base, nmf_model_25_df, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/robertpagano/metis_data/project_5/topic_modeling/topic_dfs/df_lsa_model_10.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(df_lsa_model_10, to_write)\n",
    "    \n",
    "# with open('/Users/robertpagano/metis_data/project_5/topic_modeling/topic_dfs/df_lsa_model_15.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(df_lsa_model_15, to_write)\n",
    "    \n",
    "# with open('/Users/robertpagano/metis_data/project_5/topic_modeling/topic_dfs/df_lsa_model_20.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(df_lsa_model_20, to_write)\n",
    "    \n",
    "# with open('/Users/robertpagano/metis_data/project_5/topic_modeling/topic_dfs/df_lsa_model_25.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(df_lsa_model_25, to_write)\n",
    "    \n",
    "\n",
    "# with open('/Users/robertpagano/metis_data/project_5/topic_modeling/topic_dfs/df_nmf_model_10.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(df_nmf_model_10, to_write)\n",
    "    \n",
    "# with open('/Users/robertpagano/metis_data/project_5/topic_modeling/topic_dfs/df_nmf_model_15.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(df_nmf_model_15, to_write)\n",
    "    \n",
    "# with open('/Users/robertpagano/metis_data/project_5/topic_modeling/topic_dfs/df_nmf_model_20.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(df_nmf_model_20, to_write)\n",
    "    \n",
    "# with open('/Users/robertpagano/metis_data/project_5/topic_modeling/topic_dfs/df_nmf_model_25.pickle', 'wb') as to_write:\n",
    "#     pickle.dump(df_nmf_model_25, to_write)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
