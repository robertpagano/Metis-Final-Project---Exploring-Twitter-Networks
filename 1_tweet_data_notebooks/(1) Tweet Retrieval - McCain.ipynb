{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Very basic idea here is to create a network of democrats / liberals and segment them for the upcoming primaries (i.e. centrists, leftists, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy, sys, os, logging, json\n",
    "from twitter_config import consumer_key, consumer_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='twitter_error_log_mccain.log',filemode='w', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'm just going to store JSON log files, but eventually I'm going to try to load it into postgres, because I think that makes the most since. I am using the code from https://bhaskarvk.github.io/2015/01/how-to-use-twitters-search-rest-api-most-effectively./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    " \n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True,\n",
    "                 parser=tweepy.parsers.JSONParser()\n",
    "                )\n",
    " \n",
    "if (not api):\n",
    "    print (\"Can't Authenticate\")\n",
    "    sys.exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are my search terms - I can change the text string if I want to change my terms\n",
    "# topic_search = ('aoc OR #aoc OR (alexandria AND ocasio-cortez) OR (alexandria AND ocasio) OR (alexandria AND cortez) OR ocasio-cortez OR ocasiocortez OR (alexandria AND ocasio AND cortez)')\n",
    "# topic_search = ('(captain AND marvel) OR captainmarvel OR #captainmarvel OR (brie AND larson) OR brielarson OR #brielarson')\n",
    "# topic_search = ('#QAnon OR #Qarmy OR QAnon OR Qarmy OR #WWG1WGA OR WWG1WGA OR #TrustThePlan OR #GreatAwakening')\n",
    "# topic_search = ('(3 AND batters) OR (three AND batters) OR (rules AND changes AND (baseball OR MLB)) OR (rule AND change AND (baseball OR MLB)) OR (rob AND manfred) OR (batter AND minimum)')\n",
    "topic_search = ('(john AND mccain) OR (senator AND mccain) OR (sen. AND mccain)')\n",
    "\n",
    "searchQuery = topic_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download as many search-relevant tweets from the API as possible, while respecting the rate limit.\n",
    "This code is largely taken from https://bhaskarvk.github.io/2015/01/how-to-use-twitters-search-rest-api-most-effectively./\n",
    "tweaked it to save json files every 4000 tweets, and to use logging rather than printing.\n",
    "\n",
    "ALso, adding tweet_mode = extended to every api.search method, and changing langauge as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fc160902480e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0msinceId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 new_tweets = api.search(q=searchQuery, count=tweetsPerQry, tweet_mode='extended', lang='en',\n\u001b[0;32m---> 28\u001b[0;31m                                         max_id=str(max_id - 1))\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 new_tweets = api.search(q=searchQuery, count=tweetsPerQry, tweet_mode='extended', lang='en',\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;31m# Set pagination mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    162\u001b[0m                                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_on_rate_limit_notify\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                                         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rate limit reached. Sleeping for: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msleep_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# sleep for few extra sec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;31m# if self.wait_on_rate_limit and self._reset_time is not None and \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "maxTweets = 2000000000 # Some arbitrary large number\n",
    "tweetsPerQry = 100  # this is the max the API permits\n",
    "\n",
    "# If results from a specific ID onwards are reqd, set since_id to that ID.\n",
    "# else default to no lower limit, go as far back as API allows\n",
    "sinceId = None\n",
    "\n",
    "# If results only below a specific ID are reqd, set max_id to that ID.\n",
    "# else default to no upper limit, start from the most recent tweet matching the search query.\n",
    "max_id = -1\n",
    "\n",
    "tweetCount = 0\n",
    "tweetFiles = 0\n",
    "msg =  \"Downloading max {0} tweets\".format(maxTweets)\n",
    "logging.error(msg)\n",
    "tweets = []\n",
    "while 4000*tweetFiles + tweetCount < maxTweets:\n",
    "    try:\n",
    "        if (max_id <= 0):\n",
    "            if (not sinceId):\n",
    "                new_tweets = api.search(q=searchQuery, count=tweetsPerQry, tweet_mode='extended', lang='en')\n",
    "            else:\n",
    "                new_tweets = api.search(q=searchQuery, count=tweetsPerQry, tweet_mode='extended', lang='en',\n",
    "                                        since_id=sinceId)\n",
    "        else:\n",
    "            if (not sinceId):\n",
    "                new_tweets = api.search(q=searchQuery, count=tweetsPerQry, tweet_mode='extended', lang='en',\n",
    "                                        max_id=str(max_id - 1))\n",
    "            else:\n",
    "                new_tweets = api.search(q=searchQuery, count=tweetsPerQry, tweet_mode='extended', lang='en',\n",
    "                                        max_id=str(max_id - 1),\n",
    "                                        since_id=sinceId)\n",
    "                \n",
    "        new_tweets = new_tweets['statuses']\n",
    "        if len(new_tweets) == 0:\n",
    "            msg = 'No tweets found'\n",
    "            logging.error(msg)\n",
    "            break\n",
    "        \n",
    "        tweets.extend(new_tweets)\n",
    "        tweetCount += len(new_tweets)\n",
    "        msg = \"Downloaded {0} tweets\".format(tweetCount + tweetFiles*4000)\n",
    "        logging.error(msg)\n",
    "        max_id = new_tweets[-1]['id']\n",
    "        \n",
    "        if tweetCount > 4000:\n",
    "            with open('tweets'+str(tweetFiles)+'.json', 'w', encoding=\"utf8\") as outfile:  \n",
    "                json.dump(tweets, outfile)\n",
    "            msg = \"JSON file saved\"\n",
    "            logging.error(msg)\n",
    "            tweetFiles += 1\n",
    "            tweetCount = 0\n",
    "            del tweets[:]\n",
    "                \n",
    "    except tweepy.TweepError as e:\n",
    "        msg = 'Query failed when max_id equaled {0}: {1}'.format(max_id, e)\n",
    "        logging.error(msg)\n",
    "\n",
    "if tweetCount > 0:\n",
    "    with open('tweets'+str(tweetFiles)+'.json', 'w', encoding=\"utf8\") as outfile:  \n",
    "        json.dump(tweets, outfile)\n",
    "    msg = \"JSON file saved\"\n",
    "    logging.error(msg)\n",
    "    tweetFiles += 1\n",
    "    tweetCount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1107365878625173504\n"
     ]
    }
   ],
   "source": [
    "print(max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweets0.json') as json_file:  \n",
    "    test = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4065"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Fri Mar 22 01:07:44 +0000 2019',\n",
       " 'id': 1108898016277291008,\n",
       " 'id_str': '1108898016277291008',\n",
       " 'full_text': '@fred_guttenberg You can’t reason with people like this. Hopefully, they will never have to feel your loss, and despair. @TuckerCarlson and @DLoesch are incapable of empathy.',\n",
       " 'truncated': False,\n",
       " 'display_text_range': [17, 174],\n",
       " 'entities': {'hashtags': [],\n",
       "  'symbols': [],\n",
       "  'user_mentions': [{'screen_name': 'fred_guttenberg',\n",
       "    'name': 'Fred Guttenberg',\n",
       "    'id': 967027984426242053,\n",
       "    'id_str': '967027984426242053',\n",
       "    'indices': [0, 16]},\n",
       "   {'screen_name': 'TuckerCarlson',\n",
       "    'name': 'Tucker Carlson',\n",
       "    'id': 22703645,\n",
       "    'id_str': '22703645',\n",
       "    'indices': [121, 135]},\n",
       "   {'screen_name': 'DLoesch',\n",
       "    'name': 'Dana Loesch',\n",
       "    'id': 7702542,\n",
       "    'id_str': '7702542',\n",
       "    'indices': [140, 148]}],\n",
       "  'urls': []},\n",
       " 'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
       " 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       " 'in_reply_to_status_id': 1108888828742377472,\n",
       " 'in_reply_to_status_id_str': '1108888828742377472',\n",
       " 'in_reply_to_user_id': 967027984426242053,\n",
       " 'in_reply_to_user_id_str': '967027984426242053',\n",
       " 'in_reply_to_screen_name': 'fred_guttenberg',\n",
       " 'user': {'id': 740977472246841344,\n",
       "  'id_str': '740977472246841344',\n",
       "  'name': 'Lori Ruggieri',\n",
       "  'screen_name': 'RuggieriLori',\n",
       "  'location': '',\n",
       "  'description': 'I choose to be happy😊',\n",
       "  'url': None,\n",
       "  'entities': {'description': {'urls': []}},\n",
       "  'protected': False,\n",
       "  'followers_count': 30,\n",
       "  'friends_count': 164,\n",
       "  'listed_count': 0,\n",
       "  'created_at': 'Thu Jun 09 18:42:51 +0000 2016',\n",
       "  'favourites_count': 4403,\n",
       "  'utc_offset': None,\n",
       "  'time_zone': None,\n",
       "  'geo_enabled': False,\n",
       "  'verified': False,\n",
       "  'statuses_count': 1106,\n",
       "  'lang': 'en',\n",
       "  'contributors_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'is_translation_enabled': False,\n",
       "  'profile_background_color': 'F5F8FA',\n",
       "  'profile_background_image_url': None,\n",
       "  'profile_background_image_url_https': None,\n",
       "  'profile_background_tile': False,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/824004821648805888/QEzAFJpQ_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/824004821648805888/QEzAFJpQ_normal.jpg',\n",
       "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/740977472246841344/1485293028',\n",
       "  'profile_link_color': '1DA1F2',\n",
       "  'profile_sidebar_border_color': 'C0DEED',\n",
       "  'profile_sidebar_fill_color': 'DDEEF6',\n",
       "  'profile_text_color': '333333',\n",
       "  'profile_use_background_image': True,\n",
       "  'has_extended_profile': False,\n",
       "  'default_profile': True,\n",
       "  'default_profile_image': False,\n",
       "  'following': None,\n",
       "  'follow_request_sent': None,\n",
       "  'notifications': None,\n",
       "  'translator_type': 'none'},\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'is_quote_status': False,\n",
       " 'retweet_count': 0,\n",
       " 'favorite_count': 0,\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'lang': 'en'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweets254.json') as json_file:  \n",
    "    test_last = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet = test_last[50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'retweeted_status'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b5d9fda82958>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_tweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'retweeted_status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'retweeted_status'"
     ]
    }
   ],
   "source": [
    "test_tweet['retweeted_status']['full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Sun Mar 17 20:02:45 +0000 2019',\n",
       " 'id': 1107371713065414656,\n",
       " 'id_str': '1107371713065414656',\n",
       " 'full_text': \"There's a good side to @realDonaldTrump attacking John McCain over McCain's vote against repealing the ACA: Trump is reminding America how the GOP tried repeatedly to strip healthcare from tens of millions and kill protections for preexisting conditions. #VoteBlue\",\n",
       " 'truncated': False,\n",
       " 'display_text_range': [0, 264],\n",
       " 'entities': {'hashtags': [{'text': 'VoteBlue', 'indices': [255, 264]}],\n",
       "  'symbols': [],\n",
       "  'user_mentions': [{'screen_name': 'realDonaldTrump',\n",
       "    'name': 'Donald J. Trump',\n",
       "    'id': 25073877,\n",
       "    'id_str': '25073877',\n",
       "    'indices': [23, 39]}],\n",
       "  'urls': []},\n",
       " 'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
       " 'source': '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>',\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'user': {'id': 4822119385,\n",
       "  'id_str': '4822119385',\n",
       "  'name': 'Nathaniel Spuewell',\n",
       "  'screen_name': 'natespuewell',\n",
       "  'location': 'San Francisco, CA',\n",
       "  'description': 'Focus: Russian asset in White House, thousands of kids kidnapped, attack on Constitution, open corruption, record indictments ...',\n",
       "  'url': None,\n",
       "  'entities': {'description': {'urls': []}},\n",
       "  'protected': False,\n",
       "  'followers_count': 26790,\n",
       "  'friends_count': 22680,\n",
       "  'listed_count': 118,\n",
       "  'created_at': 'Wed Jan 27 18:07:42 +0000 2016',\n",
       "  'favourites_count': 43174,\n",
       "  'utc_offset': None,\n",
       "  'time_zone': None,\n",
       "  'geo_enabled': True,\n",
       "  'verified': False,\n",
       "  'statuses_count': 56470,\n",
       "  'lang': 'en',\n",
       "  'contributors_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'is_translation_enabled': False,\n",
       "  'profile_background_color': '000000',\n",
       "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_tile': False,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/838621966181400577/3tWUcnv1_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/838621966181400577/3tWUcnv1_normal.jpg',\n",
       "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/4822119385/1477348665',\n",
       "  'profile_link_color': '1B95E0',\n",
       "  'profile_sidebar_border_color': '000000',\n",
       "  'profile_sidebar_fill_color': '000000',\n",
       "  'profile_text_color': '000000',\n",
       "  'profile_use_background_image': False,\n",
       "  'has_extended_profile': False,\n",
       "  'default_profile': False,\n",
       "  'default_profile_image': False,\n",
       "  'following': None,\n",
       "  'follow_request_sent': None,\n",
       "  'notifications': None,\n",
       "  'translator_type': 'none'},\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'is_quote_status': False,\n",
       " 'retweet_count': 5,\n",
       " 'favorite_count': 7,\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'lang': 'en'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now I have the barebones code - I'll create a new notebook where I make functions to select and clean the twitter data I need on just this one dataframe, and then I'll apply it to all of my dataframes and combine them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
